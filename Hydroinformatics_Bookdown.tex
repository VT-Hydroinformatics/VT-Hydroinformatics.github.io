% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Hydroinformatics at VT},
  pdfauthor={JP Gannon},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Hydroinformatics at VT}
\author{JP Gannon}
\date{2021-02-23}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

There will be information here about rerequisite resources and suggested readings.

\hypertarget{table-of-contents}{%
\subsection{Table of contents:}\label{table-of-contents}}

\textbf{\ref{Plotting} \protect\hyperlink{Plotting}{Intro to Plotting}}:
\emph{Introduction to plotting with ggplot.}\\
\textbf{\ref{Programming} \protect\hyperlink{Programming}{R Tidyverse Programming Basics}}:
\emph{Introduction to basic R syntax and dplyr verbs.}\\
\textbf{\ref{introactivity} \protect\hyperlink{introactivity}{Intro Skills Activity}}:
\emph{Activity to practice basic plotting and programming.}\\
\textbf{\ref{stats} \protect\hyperlink{stats}{Introduction to Basic Statistics}}:
\emph{Introcutiong to basic ways to measure a data distribution.}\\
\textbf{\ref{statsactivity} \protect\hyperlink{statsactivity}{Intro Stats Activity}}:
\emph{Activity to practice basic statistics concepts.}\\
\textbf{\ref{getdata} \protect\hyperlink{getdata}{Joins, Pivots, and USGS dataRetrieval}}:
\emph{Joins and Pivots, using USGS dataRetrieval to generate examples.}\\
\textbf{\ref{joinpivotDR} \protect\hyperlink{joinpivotDR}{Joins Pivots dataRetrieval Activity}}:
\emph{Activity to practice Joins, Pivots, and dataRetrieval.}\\
\textbf{\ref{Summative1} \protect\hyperlink{Summative1}{Summative Activity 1}}:
\emph{First summative assessment/practice.}\\
\textbf{\ref{fdcs} \protect\hyperlink{flow-duration-curves}{Flow Duration Curves}}:
\emph{Building and exploring flow duration curves.}\\
\textbf{\ref{lfas} \protect\hyperlink{lfas}{Low Flow Analysis}}:
\emph{How to calculate low-flow statistics (ex: 7Q10, 1Q10).}\\
\textbf{\ref{floods} \protect\hyperlink{floods}{Flood Frequency Analysis}}:
\emph{Flood frequency analysis and making your own functions.}

\hypertarget{Plotting}{%
\chapter{Intro to Plotting}\label{Plotting}}

\hypertarget{download-and-install-tidyverse-library}{%
\section{Download and install tidyverse library}\label{download-and-install-tidyverse-library}}

We will use the tidyverse a lot this semester. It is a suite of packages that handles plotting and data wrangling efficiently.

You only have to install the library once. You have to load it using the library() function each time you start an R session.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#install.packages("tidyverse")}
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- Attaching packages --------------------------------------- tidyverse 1.3.0 --
\end{verbatim}

\begin{verbatim}
## v ggplot2 3.3.2     v purrr   0.3.4
## v tibble  3.0.4     v dplyr   1.0.2
## v tidyr   1.1.2     v stringr 1.4.0
## v readr   1.4.0     v forcats 0.5.0
\end{verbatim}

\begin{verbatim}
## Warning: package 'ggplot2' was built under R version 3.6.2
\end{verbatim}

\begin{verbatim}
## Warning: package 'tibble' was built under R version 3.6.2
\end{verbatim}

\begin{verbatim}
## Warning: package 'tidyr' was built under R version 3.6.2
\end{verbatim}

\begin{verbatim}
## Warning: package 'readr' was built under R version 3.6.2
\end{verbatim}

\begin{verbatim}
## Warning: package 'purrr' was built under R version 3.6.2
\end{verbatim}

\begin{verbatim}
## Warning: package 'dplyr' was built under R version 3.6.2
\end{verbatim}

\begin{verbatim}
## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
\end{verbatim}

\hypertarget{reading-data}{%
\section{Reading data}\label{reading-data}}

The following lines will read in the data we will use for this exercise. Don't worry about this right now beyond running it, we will talk more about it later.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Pine }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"PINE\_Jan{-}Mar\_2010.csv"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## -- Column specification --------------------------------------------------------
## cols(
##   StationID = col_character(),
##   cfs = col_double(),
##   surrogate = col_character(),
##   datetime = col_datetime(format = ""),
##   year = col_double(),
##   quarter = col_double(),
##   month = col_double(),
##   day = col_double()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SNP }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"PINE\_NFDR\_Jan{-}Mar\_2010.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## -- Column specification --------------------------------------------------------
## cols(
##   StationID = col_character(),
##   cfs = col_double(),
##   surrogate = col_character(),
##   datetime = col_datetime(format = ""),
##   year = col_double(),
##   quarter = col_double(),
##   month = col_double(),
##   day = col_double()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RBI }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"Flashy\_Dat\_Subset.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## -- Column specification --------------------------------------------------------
## cols(
##   .default = col_double(),
##   STANAME = col_character(),
##   STATE = col_character(),
##   CLASS = col_character(),
##   AGGECOREGION = col_character()
## )
## i Use `spec()` for the full column specifications.
\end{verbatim}

\begin{figure}
\centering
\includegraphics{images/GGplot syntax.png}
\caption{Basic ggplot syntax}
\end{figure}

\hypertarget{our-first-ggplot}{%
\section{Our first ggplot}\label{our-first-ggplot}}

Let's look at the Pine data, plotting streamflow (the cfs column) by the date (datetime column). We will show the time series as a line.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ Pine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ datetime, }\AttributeTok{y =}\NormalTok{ cfs))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-5-1.pdf}

\hypertarget{change-point-type}{%
\section{Change point type}\label{change-point-type}}

Now let's make the same plot but show the data as points, using the pch parameter in geom\_point() we can change the point type to any of the following:

\begin{figure}
\centering
\includegraphics{images/pch.png}
\caption{pch options from R help file}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ Pine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ datetime, }\AttributeTok{y =}\NormalTok{ cfs))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{pch =} \DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-6-1.pdf}

\hypertarget{set-colors}{%
\section{Set colors}\label{set-colors}}

We can also ``easily'' change the color. Easily is in quotes because this often trips people up. If you put color = ``blue'' in the aesthetic function, think about what that is telling ggplot. It says ``control the color using''blue"". That doesn't make a whole lot of sense, so neither does the output\ldots{} Try it.

What happens is that if color = ``blue'' is in the aesthetic, you are telling R that the color used in the geom represents ``blue''. This is very useful if you have multiple geoms in your plot, are coloring them differently, and are building a legend. But if you are just trying to color the points, it kind of feels like R is trolling you\ldots{} doesn't it?

Take the color = ``blue'' out of the aesthetic and you're golden.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ Pine, }\FunctionTok{aes}\NormalTok{(datetime, }\AttributeTok{y =}\NormalTok{ cfs, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-7-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ Pine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ datetime, }\AttributeTok{y =}\NormalTok{ cfs))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-7-2.pdf}

\hypertarget{controlling-color-with-a-third-variable-and-other-functions}{%
\section{Controlling color with a third variable and other functions}\label{controlling-color-with-a-third-variable-and-other-functions}}

Let's plot the data as a line again, but play with it a bit.

First: make the line blue

Second: change the theme

Third: change the axis labels

Fourth: color by discharge

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ Pine, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ datetime, }\AttributeTok{y =}\NormalTok{ cfs, }\AttributeTok{color =}\NormalTok{ cfs))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Discharge (cfs)"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\FunctionTok{element\_blank}\NormalTok{())}\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-8-1.pdf}

\hypertarget{plotting-multiple-groups}{%
\section{Plotting multiple groups}\label{plotting-multiple-groups}}

The SNP dataset has two different streams: Pine and NFDR

We can look at the two of those a couple of different ways

First, make two lines, colored by the stream by adding color = to your aesthetic.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ SNP, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ datetime,}\AttributeTok{y =}\NormalTok{ cfs, }\AttributeTok{color =}\NormalTok{ StationID)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-9-1.pdf}

\hypertarget{facets}{%
\section{Facets}\label{facets}}

We can also use facets.

You must tell the facet\_wrap what variable to use to make the separate panels (facet =). It'll decide how to orient them or you can tell it how. We want them to be on top of each other so we are going to tell it we want 2 rows by setting nrow = 2. Note that we have to put the column used to make the facets in quotes after facets =

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ SNP, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ datetime,}\AttributeTok{y =}\NormalTok{ cfs)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\AttributeTok{facets =} \StringTok{"StationID"}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-10-1.pdf}

\hypertarget{two-variable-faceting}{%
\section{Two variable faceting}\label{two-variable-faceting}}

You can also use facet\_grid() to break your plots up into panels based on two variables. Below we will create a panel for each month in each watershed. Adding scales = ``free'' allows facet\_grid to change the axes. By default, all axes will be the same. This is often what we want, so we can more easily compare magnitudes, but sometimes we are looking for patterns more, so we may want to let the axes have whatever range works for the individual plots.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ SNP, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ datetime,}\AttributeTok{y =}\NormalTok{ cfs)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(StationID }\SpecialCharTok{\textasciitilde{}}\NormalTok{ month, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-11-1.pdf}

\hypertarget{boxplots}{%
\section{Boxplots}\label{boxplots}}

We can look at these data in other ways as well. A very useful way to look at the variation of two groups is to use a boxplot.

Because the data span several orders of magnitude, we will have to log the y axis to see the differences between the two streams. We do that by adding scale\_y\_log10()

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ SNP, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ StationID, }\AttributeTok{y =}\NormalTok{ cfs)) }\SpecialCharTok{+} 
  \FunctionTok{stat\_boxplot}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{scale\_y\_log10}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-12-1.pdf}

\hypertarget{more-about-color-size-etc}{%
\section{More about color, size, etc}\label{more-about-color-size-etc}}

Let's play around a bit with controlling color, point size, etc with other data.

We can control the size of points by putting size = in the aes() and color by putting color =

If you use a point type that has a background, like \#21, you can also set the background color using bg =

If points are too close together to see them all you can use a hollow point type or set the alpha lower so the points are transparent (alpha = )

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(RBI, }\FunctionTok{aes}\NormalTok{(RBI, DRAIN\_SQKM, }\AttributeTok{size =}\NormalTok{ T\_AVG\_SITE, }\AttributeTok{bg =}\NormalTok{ STATE))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{pch =} \DecValTok{21}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-13-1.pdf}

\hypertarget{multiple-geoms}{%
\section{Multiple geoms}\label{multiple-geoms}}

Finally: You can add multiple geoms to the same plot. Examples of when you might want to do this are when you are showing a line fit and want to show the points as well, or maybe showing a boxplot and want to show the data behind it. You simply add additional geom\_\ldots{} lines to add additional geoms.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(RBI, }\FunctionTok{aes}\NormalTok{(RBI, DRAIN\_SQKM, }\AttributeTok{color =}\NormalTok{ AGGECOREGION))}\SpecialCharTok{+}
  \FunctionTok{stat\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{linetype =} \DecValTok{2}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-14-1.pdf}

\hypertarget{Programming}{%
\chapter{R Tidyverse Programming Basics}\label{Programming}}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

We have messed around with plotting a bit and you've seen a little of what R can do. So now let's review or introduce you to some basics. Even if you have worked in R before, it is good to be remind of/practice with this stuff, so stay tuned in!

This exercise covers most of the same principles as two chapters in R for Data Science

Workflow: basics (\url{https://r4ds.had.co.nz/workflow-basics.html})

Data transformation (\url{https://r4ds.had.co.nz/transform.html})

\hypertarget{you-can-use-r-as-a-calculator}{%
\section{You can use R as a calculator}\label{you-can-use-r-as-a-calculator}}

If you just type numbers and operators in, R will spit out the results

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{+} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3
\end{verbatim}

\hypertarget{you-can-create-new-objects-using--}{%
\section{You can create new objects using \textless-}\label{you-can-create-new-objects-using--}}

Yea yea, = does the same thing. But use \textless-. We will call \textless- assignment or assignment operator. When we are coding in R we use \textless- to assign values to objects and = to set values for parameters in functions. Using \textless- helps us differentiate between the two. Norms for formatting are important because they help us understand what code is doing, especially when stuff gets complex.

Oh, one more thing: Surround operators with spaces. Don't code like a gorilla.

x \textless- 1 looks better than x\textless-1 and if you disagree you are wrong.

You can assign single numbers or entire chunks of data using \textless-

So if you had an object called my\_data and wanted to copy it into my\_new\_data you could do:

my\_new\_data \textless- my\_data

You can then recall/print the values in an object by just typing the name by itself.

In the code chunk below, assign a 3 to the object ``y'' and then print it out.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3
\end{verbatim}

If you want to assign multiple values, you have to put them in the function c() c means combine. R doesn't know what to do if you just give it a bunch of values with space or commas, but if you put them as arguments in the combine function, it'll make them into a vector.

Any time you need to use several values, even passing as an argument to a function, you have to put them in c() or it won't work.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)}
\NormalTok{a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4
\end{verbatim}

When you are creating objects, try to give them meaningful names so you can remember what they are. You can't have spaces or operators that mean something else as part of a name. And remember, everything is case sensitive.

Assign the value 5.4 to water\_pH and then try to recall it by typing ``water\_ph''

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{water\_pH }\OtherTok{\textless{}{-}} \FloatTok{5.4}

\CommentTok{\#water\_ph}
\end{Highlighting}
\end{Shaded}

You can also set objects equal to strings, or values that have letters in them. To do this you just have to put the value in quotes, otherwise R will think it is an object name and tell you it doesn't exist.

Try: name \textless- ``JP'' and then name \textless- JP

What happens if you forget the ending parenthesis?

Try: name \textless- "JP

R can be cryptic with it's error messages or other responses, but once you get used to them, you know exactly what is wrong when they pop up.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name }\OtherTok{\textless{}{-}} \StringTok{"JP"}
\CommentTok{\#name \textless{}{-} JP}
\end{Highlighting}
\end{Shaded}

\hypertarget{using-functions}{%
\section{Using functions}\label{using-functions}}

\includegraphics{images/Function syntax.png}

As an example, let's try the seq() function, which creates a sequence of numbers.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{1}\NormalTok{, }\AttributeTok{to =} \DecValTok{10}\NormalTok{, }\AttributeTok{by =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#or}

\FunctionTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#or}

\FunctionTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#what does this do}
\FunctionTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 10  9  8  7  6  5  4  3  2  1
\end{verbatim}

\hypertarget{read-in-some-data.}{%
\section{Read in some data.}\label{read-in-some-data.}}

For the following demonstration we will use the RBI data from a sample of USGS gages we used last class. First we will load the tidyverse library, everything we have done so far is in base R.

Important: read\_csv() is the tidyverse csv reading function, the base R function is read.csv(). read.csv() will not read your data in as a tibble, which is the format used by tidyverse functions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}

\NormalTok{rbi }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"Flashy\_Dat\_Subset.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## -- Column specification --------------------------------------------------------
## cols(
##   .default = col_double(),
##   STANAME = col_character(),
##   STATE = col_character(),
##   CLASS = col_character(),
##   AGGECOREGION = col_character()
## )
## i Use `spec()` for the full column specifications.
\end{verbatim}

\hypertarget{wait-hold-up.-what-is-a-tibble}{%
\section{Wait, hold up. What is a tibble?}\label{wait-hold-up.-what-is-a-tibble}}

Good question. It's a fancy way to store data that works well with tidyverse functions. Let's look at the rbi tibble.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(rbi)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 26
##   site_no    RBI RBIrank STANAME DRAIN_SQKM HUC02 LAT_GAGE LNG_GAGE STATE CLASS
##     <dbl>  <dbl>   <dbl> <chr>        <dbl> <dbl>    <dbl>    <dbl> <chr> <chr>
## 1 1013500 0.0584      35 Fish R~     2253.      1     47.2    -68.6 ME    Ref  
## 2 1021480 0.208      300 Old St~       76.7     1     44.9    -67.7 ME    Ref  
## 3 1022500 0.198      286 Narrag~      574.      1     44.6    -67.9 ME    Ref  
## 4 1029200 0.132      183 Seboei~      445.      1     46.1    -68.6 ME    Ref  
## 5 1030500 0.114      147 Mattaw~     3676.      1     45.5    -68.3 ME    Ref  
## 6 1031300 0.297      489 Piscat~      304.      1     45.3    -69.6 ME    Ref  
## # ... with 16 more variables: AGGECOREGION <chr>, PPTAVG_BASIN <dbl>,
## #   PPTAVG_SITE <dbl>, T_AVG_BASIN <dbl>, T_AVG_SITE <dbl>, T_MAX_BASIN <dbl>,
## #   T_MAXSTD_BASIN <dbl>, T_MAX_SITE <dbl>, T_MIN_BASIN <dbl>,
## #   T_MINSTD_BASIN <dbl>, T_MIN_SITE <dbl>, PET <dbl>, SNOW_PCT_PRECIP <dbl>,
## #   PRECIP_SEAS_IND <dbl>, FLOWYRS_1990_2009 <dbl>, wy00_09 <dbl>
\end{verbatim}

Now read in the same data with read.csv() which will NOT read the data as a tibble. How is it different? Output each one in the Console.

Knowing the data type for each column is super helpful for a few reasons\ldots. let's talk about them.

Types: int, dbl, fctr, char, logical

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rbi\_NT }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"Flashy\_Dat\_Subset.csv"}\NormalTok{)}

\FunctionTok{head}\NormalTok{(rbi\_NT)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   site_no        RBI RBIrank                                     STANAME
## 1 1013500 0.05837454      35            Fish River near Fort Kent, Maine
## 2 1021480 0.20797008     300               Old Stream near Wesley, Maine
## 3 1022500 0.19805382     286     Narraguagus River at Cherryfield, Maine
## 4 1029200 0.13151299     183         Seboeis River near Shin Pond, Maine
## 5 1030500 0.11350485     147 Mattawamkeag River near Mattawamkeag, Maine
## 6 1031300 0.29718786     489       Piscataquis River at Blanchard, Maine
##   DRAIN_SQKM HUC02 LAT_GAGE  LNG_GAGE STATE CLASS AGGECOREGION PPTAVG_BASIN
## 1     2252.7     1 47.23739 -68.58264    ME   Ref    NorthEast        97.42
## 2       76.7     1 44.93694 -67.73611    ME   Ref    NorthEast       115.39
## 3      573.6     1 44.60797 -67.93524    ME   Ref    NorthEast       120.07
## 4      444.9     1 46.14306 -68.63361    ME   Ref    NorthEast       102.19
## 5     3676.2     1 45.50097 -68.30596    ME   Ref    NorthEast       108.19
## 6      304.4     1 45.26722 -69.58389    ME   Ref    NorthEast       119.83
##   PPTAVG_SITE T_AVG_BASIN T_AVG_SITE T_MAX_BASIN T_MAXSTD_BASIN T_MAX_SITE
## 1       93.53        3.00        3.0        9.67          0.202       10.0
## 2      117.13        5.71        5.8       11.70          0.131       11.9
## 3      129.56        5.95        6.3       11.90          0.344       12.2
## 4      103.24        3.61        4.0        9.88          0.231       10.4
## 5      113.13        4.82        5.4       10.75          0.554       11.7
## 6      120.93        3.60        4.2        9.57          0.431       11.0
##   T_MIN_BASIN T_MINSTD_BASIN T_MIN_SITE   PET SNOW_PCT_PRECIP PRECIP_SEAS_IND
## 1       -2.49          0.269       -2.7 504.7            36.9           0.102
## 2       -0.85          0.123       -0.6 554.2            39.5           0.046
## 3        0.06          0.873        1.4 553.1            38.2           0.047
## 4       -2.13          0.216       -1.5 513.0            36.4           0.070
## 5       -1.49          0.251       -1.2 540.8            37.2           0.033
## 6       -2.46          0.268       -1.7 495.8            40.2           0.030
##   FLOWYRS_1990_2009 wy00_09
## 1                20      10
## 2                11      10
## 3                20      10
## 4                11      10
## 5                20      10
## 6                13      10
\end{verbatim}

\hypertarget{data-wrangling-in-dplyr}{%
\section{Data wrangling in dplyr}\label{data-wrangling-in-dplyr}}

If you forget syntax or what the following functions do, here is an excellent cheat sheet: \url{https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf}

We will demo five functions below:

\hypertarget{filter---returns-rows-that-meet-specified-conditions}{%
\subsection{filter() - returns rows that meet specified conditions}\label{filter---returns-rows-that-meet-specified-conditions}}

\hypertarget{arrange---reorders-rows}{%
\subsection{arrange() - reorders rows}\label{arrange---reorders-rows}}

\hypertarget{select---pull-out-variables-columns}{%
\subsection{select() - pull out variables (columns)}\label{select---pull-out-variables-columns}}

\hypertarget{mutate---create-new-variables-columns-or-reformat-existing-ones}{%
\subsection{mutate() - create new variables (columns) or reformat existing ones}\label{mutate---create-new-variables-columns-or-reformat-existing-ones}}

\hypertarget{summarize---collapse-groups-of-values-into-summary-stats}{%
\subsection{summarize() - collapse groups of values into summary stats}\label{summarize---collapse-groups-of-values-into-summary-stats}}

With all of these, the first argument is the data and then the arguments after that specify what you want the function to do.

\includegraphics{images/dplyr functions.png}

\hypertarget{filter}{%
\section{Filter}\label{filter}}

Write an expression that returns data in rbi for the state of Maine (ME)

Operators:\\
== equal\\
!= not equal\\
\textgreater= , \textless= greater than or equal to, less than or equal to\\
\textgreater, \textless{} greater than or less then\\
\%in\% included in a list of values\\
\& and\\
\textbar{} or

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(rbi, STATE }\SpecialCharTok{==} \StringTok{"ME"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 13 x 26
##    site_no    RBI RBIrank STANAME DRAIN_SQKM HUC02 LAT_GAGE LNG_GAGE STATE CLASS
##      <dbl>  <dbl>   <dbl> <chr>        <dbl> <dbl>    <dbl>    <dbl> <chr> <chr>
##  1 1013500 0.0584      35 Fish R~     2253.      1     47.2    -68.6 ME    Ref  
##  2 1021480 0.208      300 Old St~       76.7     1     44.9    -67.7 ME    Ref  
##  3 1022500 0.198      286 Narrag~      574.      1     44.6    -67.9 ME    Ref  
##  4 1029200 0.132      183 Seboei~      445.      1     46.1    -68.6 ME    Ref  
##  5 1030500 0.114      147 Mattaw~     3676.      1     45.5    -68.3 ME    Ref  
##  6 1031300 0.297      489 Piscat~      304.      1     45.3    -69.6 ME    Ref  
##  7 1031500 0.320      545 Piscat~      769       1     45.2    -69.3 ME    Ref  
##  8 1037380 0.318      537 Ducktr~       39       1     44.3    -69.1 ME    Ref  
##  9 1044550 0.242      360 Spence~      500.      1     45.3    -70.2 ME    Ref  
## 10 1047000 0.344      608 Carrab~      909.      1     44.9    -70.0 ME    Ref  
## 11 1054200 0.492      805 Wild R~      181       1     44.4    -71.0 ME    Ref  
## 12 1055000 0.450      762 Swift ~      251.      1     44.6    -70.6 ME    Ref  
## 13 1057000 0.326      561 Little~      191.      1     44.3    -70.5 ME    Ref  
## # ... with 16 more variables: AGGECOREGION <chr>, PPTAVG_BASIN <dbl>,
## #   PPTAVG_SITE <dbl>, T_AVG_BASIN <dbl>, T_AVG_SITE <dbl>, T_MAX_BASIN <dbl>,
## #   T_MAXSTD_BASIN <dbl>, T_MAX_SITE <dbl>, T_MIN_BASIN <dbl>,
## #   T_MINSTD_BASIN <dbl>, T_MIN_SITE <dbl>, PET <dbl>, SNOW_PCT_PRECIP <dbl>,
## #   PRECIP_SEAS_IND <dbl>, FLOWYRS_1990_2009 <dbl>, wy00_09 <dbl>
\end{verbatim}

\hypertarget{multiple-conditions}{%
\subsection{Multiple conditions}\label{multiple-conditions}}

How many gages are there in Maine with an rbi greater than 0.25

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(rbi, STATE }\SpecialCharTok{==} \StringTok{"ME"} \SpecialCharTok{\&}\NormalTok{ RBI }\SpecialCharTok{\textgreater{}} \FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 7 x 26
##   site_no   RBI RBIrank STANAME DRAIN_SQKM HUC02 LAT_GAGE LNG_GAGE STATE CLASS
##     <dbl> <dbl>   <dbl> <chr>        <dbl> <dbl>    <dbl>    <dbl> <chr> <chr>
## 1 1031300 0.297     489 Piscat~       304.     1     45.3    -69.6 ME    Ref  
## 2 1031500 0.320     545 Piscat~       769      1     45.2    -69.3 ME    Ref  
## 3 1037380 0.318     537 Ducktr~        39      1     44.3    -69.1 ME    Ref  
## 4 1047000 0.344     608 Carrab~       909.     1     44.9    -70.0 ME    Ref  
## 5 1054200 0.492     805 Wild R~       181      1     44.4    -71.0 ME    Ref  
## 6 1055000 0.450     762 Swift ~       251.     1     44.6    -70.6 ME    Ref  
## 7 1057000 0.326     561 Little~       191.     1     44.3    -70.5 ME    Ref  
## # ... with 16 more variables: AGGECOREGION <chr>, PPTAVG_BASIN <dbl>,
## #   PPTAVG_SITE <dbl>, T_AVG_BASIN <dbl>, T_AVG_SITE <dbl>, T_MAX_BASIN <dbl>,
## #   T_MAXSTD_BASIN <dbl>, T_MAX_SITE <dbl>, T_MIN_BASIN <dbl>,
## #   T_MINSTD_BASIN <dbl>, T_MIN_SITE <dbl>, PET <dbl>, SNOW_PCT_PRECIP <dbl>,
## #   PRECIP_SEAS_IND <dbl>, FLOWYRS_1990_2009 <dbl>, wy00_09 <dbl>
\end{verbatim}

\hypertarget{arrange}{%
\section{Arrange}\label{arrange}}

Arrange sorts by a column in your dataset.

Sort the rbi data by the RBI column in ascending and then descending order

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{arrange}\NormalTok{(rbi, RBI)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 49 x 26
##    site_no    RBI RBIrank STANAME DRAIN_SQKM HUC02 LAT_GAGE LNG_GAGE STATE CLASS
##      <dbl>  <dbl>   <dbl> <chr>        <dbl> <dbl>    <dbl>    <dbl> <chr> <chr>
##  1 1305500 0.0464      18 SWAN R~       21.3     2     40.8    -73.0 NY    Non-~
##  2 1013500 0.0584      35 Fish R~     2253.      1     47.2    -68.6 ME    Ref  
##  3 1306460 0.0587      37 CONNET~       55.7     2     40.8    -73.2 NY    Non-~
##  4 1030500 0.114      147 Mattaw~     3676.      1     45.5    -68.3 ME    Ref  
##  5 1029200 0.132      183 Seboei~      445.      1     46.1    -68.6 ME    Ref  
##  6 1117468 0.172      244 BEAVER~       25.3     1     41.5    -71.6 RI    Ref  
##  7 1022500 0.198      286 Narrag~      574.      1     44.6    -67.9 ME    Ref  
##  8 1021480 0.208      300 Old St~       76.7     1     44.9    -67.7 ME    Ref  
##  9 1162500 0.213      311 PRIEST~       49.7     1     42.7    -72.1 MA    Ref  
## 10 1117370 0.230      338 QUEEN ~       50.5     1     41.5    -71.6 RI    Ref  
## # ... with 39 more rows, and 16 more variables: AGGECOREGION <chr>,
## #   PPTAVG_BASIN <dbl>, PPTAVG_SITE <dbl>, T_AVG_BASIN <dbl>, T_AVG_SITE <dbl>,
## #   T_MAX_BASIN <dbl>, T_MAXSTD_BASIN <dbl>, T_MAX_SITE <dbl>,
## #   T_MIN_BASIN <dbl>, T_MINSTD_BASIN <dbl>, T_MIN_SITE <dbl>, PET <dbl>,
## #   SNOW_PCT_PRECIP <dbl>, PRECIP_SEAS_IND <dbl>, FLOWYRS_1990_2009 <dbl>,
## #   wy00_09 <dbl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{arrange}\NormalTok{(rbi, }\FunctionTok{desc}\NormalTok{(RBI))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 49 x 26
##    site_no   RBI RBIrank STANAME DRAIN_SQKM HUC02 LAT_GAGE LNG_GAGE STATE CLASS
##      <dbl> <dbl>   <dbl> <chr>        <dbl> <dbl>    <dbl>    <dbl> <chr> <chr>
##  1 1311500 0.856    1017 VALLEY~       18.1     2     40.7    -73.7 NY    Non-~
##  2 1054200 0.492     805 Wild R~      181       1     44.4    -71.0 ME    Ref  
##  3 1187300 0.487     800 HUBBAR~       53.9     1     42.0    -72.9 MA    Ref  
##  4 1105600 0.484     797 OLD SW~       12.7     1     42.2    -70.9 MA    Non-~
##  5 1055000 0.450     762 Swift ~      251.      1     44.6    -70.6 ME    Ref  
##  6 1195100 0.430     744 INDIAN~       14.8     1     41.3    -72.5 CT    Ref  
##  7 1181000 0.420     732 WEST B~      244.      1     42.2    -72.9 MA    Ref  
##  8 1350000 0.414     721 SCHOHA~      612.      2     42.3    -74.4 NY    Ref  
##  9 1121000 0.404     710 MOUNT ~       70.3     1     41.8    -72.2 CT    Ref  
## 10 1169000 0.395     688 NORTH ~      231.      1     42.6    -72.7 MA    Ref  
## # ... with 39 more rows, and 16 more variables: AGGECOREGION <chr>,
## #   PPTAVG_BASIN <dbl>, PPTAVG_SITE <dbl>, T_AVG_BASIN <dbl>, T_AVG_SITE <dbl>,
## #   T_MAX_BASIN <dbl>, T_MAXSTD_BASIN <dbl>, T_MAX_SITE <dbl>,
## #   T_MIN_BASIN <dbl>, T_MINSTD_BASIN <dbl>, T_MIN_SITE <dbl>, PET <dbl>,
## #   SNOW_PCT_PRECIP <dbl>, PRECIP_SEAS_IND <dbl>, FLOWYRS_1990_2009 <dbl>,
## #   wy00_09 <dbl>
\end{verbatim}

\hypertarget{select}{%
\section{Select}\label{select}}

There are too many columns! You will often want to do this when you are manipulating the structure of your data and need to trim it down to only include what you will use.

Select Site name, state, and RBI from the rbi data

Note they come back in the order you put them in in the function, not the order they were in in the original data.

You can do a lot more with select, especially when you need to select a bunch of columns but don't want to type them all out. But we don't need to cover all that today. For a taste though, if you want to select a group of columns you can specify the first and last with a colon in between (first:last) and it'll return all of them. Select the rbi columns from site\_no to DRAIN\_SQKM.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(rbi, STANAME, STATE, RBI)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 49 x 3
##    STANAME                                      STATE    RBI
##    <chr>                                        <chr>  <dbl>
##  1 Fish River near Fort Kent, Maine             ME    0.0584
##  2 Old Stream near Wesley, Maine                ME    0.208 
##  3 Narraguagus River at Cherryfield, Maine      ME    0.198 
##  4 Seboeis River near Shin Pond, Maine          ME    0.132 
##  5 Mattawamkeag River near Mattawamkeag, Maine  ME    0.114 
##  6 Piscataquis River at Blanchard, Maine        ME    0.297 
##  7 Piscataquis River near Dover-Foxcroft, Maine ME    0.320 
##  8 Ducktrap River near Lincolnville, Maine      ME    0.318 
##  9 Spencer Stream near Grand Falls, Maine       ME    0.242 
## 10 Carrabassett River near North Anson, Maine   ME    0.344 
## # ... with 39 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(rbi, site\_no}\SpecialCharTok{:}\NormalTok{DRAIN\_SQKM)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 49 x 5
##    site_no    RBI RBIrank STANAME                                     DRAIN_SQKM
##      <dbl>  <dbl>   <dbl> <chr>                                            <dbl>
##  1 1013500 0.0584      35 Fish River near Fort Kent, Maine                2253. 
##  2 1021480 0.208      300 Old Stream near Wesley, Maine                     76.7
##  3 1022500 0.198      286 Narraguagus River at Cherryfield, Maine          574. 
##  4 1029200 0.132      183 Seboeis River near Shin Pond, Maine              445. 
##  5 1030500 0.114      147 Mattawamkeag River near Mattawamkeag, Maine     3676. 
##  6 1031300 0.297      489 Piscataquis River at Blanchard, Maine            304. 
##  7 1031500 0.320      545 Piscataquis River near Dover-Foxcroft, Mai~      769  
##  8 1037380 0.318      537 Ducktrap River near Lincolnville, Maine           39  
##  9 1044550 0.242      360 Spencer Stream near Grand Falls, Maine           500. 
## 10 1047000 0.344      608 Carrabassett River near North Anson, Maine       909. 
## # ... with 39 more rows
\end{verbatim}

\hypertarget{mutate}{%
\section{Mutate}\label{mutate}}

Use mutate to add new columns based on additional ones. Common uses are to create a column of data in different units, or to calculate something based on two columns. You can also use it to just update a column, by naming the new column the same as the original one (but be careful because you'll lose the original one!). I commonly use this when I am changing the datatype of a column, say from a character to a factor or a string to a date.

Create a new column in rbi called T\_RANGE by subtracting T\_MIN\_SITE from T\_MAX\_SITE

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mutate}\NormalTok{(rbi, }\AttributeTok{T\_RANGE =}\NormalTok{ T\_MAX\_SITE }\SpecialCharTok{{-}}\NormalTok{ T\_MIN\_SITE)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 49 x 27
##    site_no    RBI RBIrank STANAME DRAIN_SQKM HUC02 LAT_GAGE LNG_GAGE STATE CLASS
##      <dbl>  <dbl>   <dbl> <chr>        <dbl> <dbl>    <dbl>    <dbl> <chr> <chr>
##  1 1013500 0.0584      35 Fish R~     2253.      1     47.2    -68.6 ME    Ref  
##  2 1021480 0.208      300 Old St~       76.7     1     44.9    -67.7 ME    Ref  
##  3 1022500 0.198      286 Narrag~      574.      1     44.6    -67.9 ME    Ref  
##  4 1029200 0.132      183 Seboei~      445.      1     46.1    -68.6 ME    Ref  
##  5 1030500 0.114      147 Mattaw~     3676.      1     45.5    -68.3 ME    Ref  
##  6 1031300 0.297      489 Piscat~      304.      1     45.3    -69.6 ME    Ref  
##  7 1031500 0.320      545 Piscat~      769       1     45.2    -69.3 ME    Ref  
##  8 1037380 0.318      537 Ducktr~       39       1     44.3    -69.1 ME    Ref  
##  9 1044550 0.242      360 Spence~      500.      1     45.3    -70.2 ME    Ref  
## 10 1047000 0.344      608 Carrab~      909.      1     44.9    -70.0 ME    Ref  
## # ... with 39 more rows, and 17 more variables: AGGECOREGION <chr>,
## #   PPTAVG_BASIN <dbl>, PPTAVG_SITE <dbl>, T_AVG_BASIN <dbl>, T_AVG_SITE <dbl>,
## #   T_MAX_BASIN <dbl>, T_MAXSTD_BASIN <dbl>, T_MAX_SITE <dbl>,
## #   T_MIN_BASIN <dbl>, T_MINSTD_BASIN <dbl>, T_MIN_SITE <dbl>, PET <dbl>,
## #   SNOW_PCT_PRECIP <dbl>, PRECIP_SEAS_IND <dbl>, FLOWYRS_1990_2009 <dbl>,
## #   wy00_09 <dbl>, T_RANGE <dbl>
\end{verbatim}

When downloading data from the USGS through R, you have to enter the gage ID as a character, even though they are all made up of numbers. So to practice doing this, update the site\_no column to be a character datatype

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mutate}\NormalTok{(rbi, }\AttributeTok{site\_no =} \FunctionTok{as.character}\NormalTok{(site\_no))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 49 x 26
##    site_no    RBI RBIrank STANAME DRAIN_SQKM HUC02 LAT_GAGE LNG_GAGE STATE CLASS
##    <chr>    <dbl>   <dbl> <chr>        <dbl> <dbl>    <dbl>    <dbl> <chr> <chr>
##  1 1013500 0.0584      35 Fish R~     2253.      1     47.2    -68.6 ME    Ref  
##  2 1021480 0.208      300 Old St~       76.7     1     44.9    -67.7 ME    Ref  
##  3 1022500 0.198      286 Narrag~      574.      1     44.6    -67.9 ME    Ref  
##  4 1029200 0.132      183 Seboei~      445.      1     46.1    -68.6 ME    Ref  
##  5 1030500 0.114      147 Mattaw~     3676.      1     45.5    -68.3 ME    Ref  
##  6 1031300 0.297      489 Piscat~      304.      1     45.3    -69.6 ME    Ref  
##  7 1031500 0.320      545 Piscat~      769       1     45.2    -69.3 ME    Ref  
##  8 1037380 0.318      537 Ducktr~       39       1     44.3    -69.1 ME    Ref  
##  9 1044550 0.242      360 Spence~      500.      1     45.3    -70.2 ME    Ref  
## 10 1047000 0.344      608 Carrab~      909.      1     44.9    -70.0 ME    Ref  
## # ... with 39 more rows, and 16 more variables: AGGECOREGION <chr>,
## #   PPTAVG_BASIN <dbl>, PPTAVG_SITE <dbl>, T_AVG_BASIN <dbl>, T_AVG_SITE <dbl>,
## #   T_MAX_BASIN <dbl>, T_MAXSTD_BASIN <dbl>, T_MAX_SITE <dbl>,
## #   T_MIN_BASIN <dbl>, T_MINSTD_BASIN <dbl>, T_MIN_SITE <dbl>, PET <dbl>,
## #   SNOW_PCT_PRECIP <dbl>, PRECIP_SEAS_IND <dbl>, FLOWYRS_1990_2009 <dbl>,
## #   wy00_09 <dbl>
\end{verbatim}

\hypertarget{summarize}{%
\section{Summarize}\label{summarize}}

Summarize will perform an operation on all of your data, or groups if you assign groups.

Use summarize to compute the mean, min, and max rbi

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarize}\NormalTok{(rbi, }\AttributeTok{meanrbi =} \FunctionTok{mean}\NormalTok{(RBI), }\AttributeTok{maxrbi =} \FunctionTok{max}\NormalTok{(RBI), }\AttributeTok{minrbi =} \FunctionTok{min}\NormalTok{(RBI))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##   meanrbi maxrbi minrbi
##     <dbl>  <dbl>  <dbl>
## 1   0.316  0.856 0.0464
\end{verbatim}

Now use the group function to group by state and then summarize in the same way as above

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rbistate }\OtherTok{\textless{}{-}} \FunctionTok{group\_by}\NormalTok{(rbi, STATE)}
\FunctionTok{summarize}\NormalTok{(rbistate, }\AttributeTok{meanrbi =} \FunctionTok{mean}\NormalTok{(RBI), }\AttributeTok{maxrbi =} \FunctionTok{max}\NormalTok{(RBI), }\AttributeTok{minrbi =} \FunctionTok{min}\NormalTok{(RBI))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 7 x 4
##   STATE meanrbi maxrbi minrbi
##   <chr>   <dbl>  <dbl>  <dbl>
## 1 CT      0.366  0.430 0.295 
## 2 MA      0.367  0.487 0.213 
## 3 ME      0.269  0.492 0.0584
## 4 NH      0.336  0.368 0.265 
## 5 NY      0.342  0.856 0.0464
## 6 RI      0.201  0.230 0.172 
## 7 VT      0.299  0.365 0.231
\end{verbatim}

\hypertarget{multiple-operations-with-pipes}{%
\section{Multiple operations with pipes}\label{multiple-operations-with-pipes}}

The pipe operator \%\textgreater\% allows you to perform multiple operations in a sequence without saving intermediate steps. Not only is this more efficient, but structuring operations with pipes is also more intuitive than nesting functions within functions (the other way you can do multiple operations).

\hypertarget{lets-say-we-want-to-tell-r-to-make-a-pbj-sandwich-by-using-the-pbbread-jbread-and-joinslices-functions-and-the-data-ingredients.-if-we-do-this-saving-each-step-if-would-look-like-this}{%
\subsection{Let's say we want to tell R to make a PB\&J sandwich by using the pbbread(), jbread(), and joinslices() functions and the data ``ingredients''. If we do this saving each step if would look like this:}\label{lets-say-we-want-to-tell-r-to-make-a-pbj-sandwich-by-using-the-pbbread-jbread-and-joinslices-functions-and-the-data-ingredients.-if-we-do-this-saving-each-step-if-would-look-like-this}}

sando \textless- pbbread(ingredients)

sando \textless- jbread(sando)

sando \textless- joinslices(sando)

\hypertarget{if-we-nest-the-functions-together-we-get-this}{%
\subsection{If we nest the functions together we get this}\label{if-we-nest-the-functions-together-we-get-this}}

joinslice(jbread(pbbread(ingredients)))

Efficient\ldots{} but tough to read/interpret

\hypertarget{using-the-pipe-it-would-look-like-this}{%
\subsection{Using the pipe it would look like this}\label{using-the-pipe-it-would-look-like-this}}

ingredients \%\textgreater\%\\
pbbread() \%\textgreater\%\\
jbread() \%\textgreater\%\\
joinslices()

Much easier to follow!

\hypertarget{when-you-use-the-pipe-it-basically-takes-whatever-came-out-of-the-first-function-and-puts-it-into-the-data-argument-for-the-next-one}{%
\subsection{When you use the pipe, it basically takes whatever came out of the first function and puts it into the data argument for the next one}\label{when-you-use-the-pipe-it-basically-takes-whatever-came-out-of-the-first-function-and-puts-it-into-the-data-argument-for-the-next-one}}

\textbf{so rbi \%\textgreater\% group\_by(STATE) is the same as group\_by(rbi, STATE)}

Take the groupby and summarize code from above and perform the operation using the pipe

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rbi }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(STATE) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{meanrbi =} \FunctionTok{mean}\NormalTok{(RBI), }\AttributeTok{maxrbi =} \FunctionTok{max}\NormalTok{(RBI), }\AttributeTok{minrbi =} \FunctionTok{min}\NormalTok{(RBI))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 7 x 4
##   STATE meanrbi maxrbi minrbi
##   <chr>   <dbl>  <dbl>  <dbl>
## 1 CT      0.366  0.430 0.295 
## 2 MA      0.367  0.487 0.213 
## 3 ME      0.269  0.492 0.0584
## 4 NH      0.336  0.368 0.265 
## 5 NY      0.342  0.856 0.0464
## 6 RI      0.201  0.230 0.172 
## 7 VT      0.299  0.365 0.231
\end{verbatim}

\hypertarget{save-your-results-to-a-new-tibble}{%
\section{Save your results to a new tibble}\label{save-your-results-to-a-new-tibble}}

We have just been writing everything to the screen so we can see what we are doing\ldots{} In order to save anything we do with these functions to work with it later, we just have to use the assignment operator (\textless-) to store the data.

One kind of awesome thing about the assignment operator is that it works both ways\ldots{}

x \textless- 3 and 3 -\textgreater{} x do the same thing (WHAT?!)

So you can do the assignment at the beginning of the end of your dplyr workings, whatever you like best.

Use the assignment operator to save the summary table you just made.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stateRBIs }\OtherTok{\textless{}{-}}\NormalTok{ rbi }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(STATE) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{meanrbi =} \FunctionTok{mean}\NormalTok{(RBI), }\AttributeTok{maxrbi =} \FunctionTok{max}\NormalTok{(RBI), }\AttributeTok{minrbi =} \FunctionTok{min}\NormalTok{(RBI))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Notice when you do this it doesn\textquotesingle{}t output the result... }
\CommentTok{\# You can see what you did by clickon in stateRBIs in your environment panel}
\CommentTok{\# or just type stateRBIs}

\NormalTok{stateRBIs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 7 x 4
##   STATE meanrbi maxrbi minrbi
##   <chr>   <dbl>  <dbl>  <dbl>
## 1 CT      0.366  0.430 0.295 
## 2 MA      0.367  0.487 0.213 
## 3 ME      0.269  0.492 0.0584
## 4 NH      0.336  0.368 0.265 
## 5 NY      0.342  0.856 0.0464
## 6 RI      0.201  0.230 0.172 
## 7 VT      0.299  0.365 0.231
\end{verbatim}

\hypertarget{what-about-nas}{%
\section{What about NAs?}\label{what-about-nas}}

We will talk more about this when we discuss stats, but some operations will fail if there are NA's in the data. If appropriate, you can tell functions like mean() to ignore NAs. You can also use drop\_na() if you're working with a tibble. But be aware if you use that and save the result, drop\_na() gets rid of the whole row, not just the NA. Because what would you replace it with\ldots. an NA?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\ConstantTok{NA}\NormalTok{)}
\FunctionTok{mean}\NormalTok{(x, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.5
\end{verbatim}

\hypertarget{what-are-some-things-you-think-ill-ask-you-to-do-for-the-activity-next-class}{%
\section{What are some things you think I'll ask you to do for the activity next class?}\label{what-are-some-things-you-think-ill-ask-you-to-do-for-the-activity-next-class}}

\hypertarget{introactivity}{%
\chapter{Intro Skills Activity}\label{introactivity}}

\hypertarget{problem-1}{%
\section{Problem 1}\label{problem-1}}

Load the tidyverse and lubridate libraries.

Read in the PINE\_NFDR\_Jan-Mar\_2010 csv using read\_csv()

Make a plot with the date on the x axis, discharge on the y axis. Show the discharge of the two watersheds as a line, coloring by watershed (StationID)

\hypertarget{problem-2}{%
\section{Problem 2}\label{problem-2}}

Make a boxplot to compare the discharge of Pine to NFDR for February 2010.

Hint: use the pipe operator and the filter() function.

Hint2: when you filter dates, you have to let R know you're giving it a date. You can do this by using the mdy() function from lubridate.

\hypertarget{problem-3}{%
\section{Problem 3}\label{problem-3}}

Read in the Flashy Dat Subset file.

For only sites in ME, NH, and VT: Plot PET (Potential Evapotranspiration) on the X axis and RBI (flashiness index) on the Y axis. Color the points based on what state they are in. Use the classic ggplot theme.

\hypertarget{problem-4}{%
\section{Problem 4}\label{problem-4}}

We want to look at the amount of snow for each site in the flashy dataset. Problem is, we are only given the average amount of total precip (PPTAVG\_BASIN) and the percentage of snow (SNOW\_PCT\_PRECIP).

Create a new column in the dataset called SNOW\_AVG\_BASIN and make it equal to the average total precip times the percentage of snow (careful with the percentage number).

Make a barplot showing the amount of snow for each site in Maine. Put station name on the x axis and snow amount on the y. You have to add something to geom\_bar() to use it for a 2 variable plot\ldots{} check out the ggplot cheatsheet or do a quick internet search.

The x axis of the resulting plot looks terrible! Can you figure out how to rotate the X axis labels so we can read them?

\hypertarget{problem-5}{%
\section{Problem 5}\label{problem-5}}

Create a new tibble that contains the min, max, and mean PET for each state. Sort the tibble by mean PET from high to low. Give your columns meaningful names within the summarize function or using rename().

Be sure your code outputs the tibble.

\hypertarget{problem-6}{%
\section{Problem 6}\label{problem-6}}

Take the tibble from problem 5. Create a new column that is the Range of the PET (max PET - min PET). Then get rid of the max PET and min PET columns so the tibble just has columns for State, mean PET, and PET range.

Be sure your code outputs the tibble.

\hypertarget{stats}{%
\chapter{Introduction to Basic Statistics}\label{stats}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(patchwork)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'patchwork' was built under R version 3.6.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{theme\_set}\NormalTok{(}\FunctionTok{theme\_classic}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\hypertarget{reading-for-this-section-statistical-methods-in-water-resources-chapter-1}{%
\section{Reading for this section: Statistical Methods in Water Resources: Chapter 1}\label{reading-for-this-section-statistical-methods-in-water-resources-chapter-1}}

\url{https://pubs.usgs.gov/tm/04/a03/tm4a3.pdf}

\hypertarget{questions-for-today}{%
\section{Questions for today:}\label{questions-for-today}}

\hypertarget{what-is-the-difference-between-a-sample-and-a-population}{%
\subsection{What is the difference between a sample and a population?}\label{what-is-the-difference-between-a-sample-and-a-population}}

\hypertarget{how-do-we-look-at-the-distribution-of-data-in-a-sample}{%
\subsection{How do we look at the distribution of data in a sample?}\label{how-do-we-look-at-the-distribution-of-data-in-a-sample}}

\hypertarget{how-do-we-measure-aspects-of-a-distribution}{%
\subsection{How do we measure aspects of a distribution?}\label{how-do-we-measure-aspects-of-a-distribution}}

\hypertarget{what-is-a-normal-distribution}{%
\subsection{What is a normal distribution?}\label{what-is-a-normal-distribution}}

First let's generate some synthetic data and talk about how to visualize it.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#generate a normal distribution}
\NormalTok{ExNorm }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{1000}\NormalTok{, }\AttributeTok{mean =} \DecValTok{5}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as\_tibble}\NormalTok{()}

\CommentTok{\#look at distributions}
\CommentTok{\#histogram}
\NormalTok{ExNorm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(value)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-42-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#pdf}
\NormalTok{ExNorm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(value)) }\SpecialCharTok{+}
  \FunctionTok{stat\_density}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-42-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Let\textquotesingle{}s generate a plot that makes comparing these two easier}
\end{Highlighting}
\end{Shaded}

\hypertarget{stack-plots-to-compare-histogram-and-pdf}{%
\subsection{Stack plots to compare histogram and pdf}\label{stack-plots-to-compare-histogram-and-pdf}}

We will save each plot as ggplot object and then output them using the patchwork package (loaded in the setup chunk).

What is the difference between a histogram and a pdf?\\
What features of the histogram are preserved? Which are lost?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#histogram}
\NormalTok{exhist }\OtherTok{\textless{}{-}}\NormalTok{ ExNorm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(value)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}

\CommentTok{\#pdf}
\NormalTok{expdf }\OtherTok{\textless{}{-}}\NormalTok{ ExNorm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(value)) }\SpecialCharTok{+}
  \FunctionTok{stat\_density}\NormalTok{()}

\CommentTok{\#put the plots side by side with + or on top of each other with /}
\NormalTok{exhist}\SpecialCharTok{/}\NormalTok{expdf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-43-1.pdf}

\hypertarget{what-is-the-difference-between-a-sample-and-a-population.}{%
\section{What is the difference between a sample and a population.}\label{what-is-the-difference-between-a-sample-and-a-population.}}

Simply put: a population is the thing you are trying to measure. A sample is the data you measure in an effort to measure the population. A sample is a subset of a population.

Let's write some code for an example:

We will create a POPULATION that is a large set of numbers. Think of this is as the concentration of Calcium in every bit of water in a lake. Then we will create a SAMPLE by randomly grabbing values from the POPULATION. This simulates us going around in a boat and taking grab samples in an effort to figure out the concentration of calcium in the lake.

We can then run this code a bunch of times, you'll get a different sample each time. You can also take a smaller or larger number of samples by changing ``size'' in the sample() function.

How does your sample distribution look similar or different from the population?\\
Why does the sample change every time you run it?\\
What happens as you increase or decrease the number of samples?\\
What happens if you set the number of samples to the size of the population?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all\_the\_water }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{10000}\NormalTok{, }\AttributeTok{mean =} \DecValTok{6}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as\_tibble}\NormalTok{()}

\NormalTok{sample\_of\_water }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(all\_the\_water}\SpecialCharTok{$}\NormalTok{value, }\AttributeTok{size =} \DecValTok{100}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as\_tibble}\NormalTok{()}

\NormalTok{population\_hist }\OtherTok{\textless{}{-}}\NormalTok{ all\_the\_water }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(value))}\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Population: All the water in the lake"}\NormalTok{)}

\NormalTok{sample\_hist }\OtherTok{\textless{}{-}}\NormalTok{ sample\_of\_water }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(value))}\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Your sample of the lake"}\NormalTok{)}

\NormalTok{population\_hist }\SpecialCharTok{+}\NormalTok{ sample\_hist}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-44-1.pdf}

\hypertarget{measuring-our-sample-distribution-central-tendency.}{%
\section{Measuring our sample distribution: central tendency.}\label{measuring-our-sample-distribution-central-tendency.}}

When we take a sample of a population, there are a few things we will want to measure about the distribution of values: where is the middle, how variable is it, and is it skewed to one side or another?

The first of these, ``where is the middle?'' is addressed with measures of central tendency. We will discuss three possible ways to measure this. The mean, median, and weighted mean.

To explain the importance of choosing between the mean and median, we will first import some discharge data. Read in the PINE discharge data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pineQ }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"PINE\_Jan{-}Mar\_2010.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## -- Column specification --------------------------------------------------------
## cols(
##   StationID = col_character(),
##   cfs = col_double(),
##   surrogate = col_character(),
##   datetime = col_datetime(format = ""),
##   year = col_double(),
##   quarter = col_double(),
##   month = col_double(),
##   day = col_double()
## )
\end{verbatim}

To find the mean (average), you just sum up all the values in your sample and divide by the number of values.

To find the median, you put the values IN ORDER, and choose the middle value. The middle value is the one where there are the same number of values higher than that value as there are values lower than it.

Because it uses the order of the values rather than just the values themselves, the median is resistant to skewed distributions. This means it is less effected by very large or very small values compared to most values in the sample data.

Let's look at our normal distribution from earlier (ExNorm) compared to the Pine watershed discharge (pineQ)

Note that distributions like pineQ, that are positively skewed, are very common in environmental data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Calculate mean and median for cfs in pineQ and values in ExNorm}
\NormalTok{pineMean }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(pineQ}\SpecialCharTok{$}\NormalTok{cfs)}
\NormalTok{pineMedian }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(pineQ}\SpecialCharTok{$}\NormalTok{cfs)}

\NormalTok{xmean }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(ExNorm}\SpecialCharTok{$}\NormalTok{value)}
\NormalTok{xmedian }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(ExNorm}\SpecialCharTok{$}\NormalTok{value)}

\CommentTok{\#plot mean and median on the ExNorm distribution}
\NormalTok{Ex }\OtherTok{\textless{}{-}}\NormalTok{ ExNorm }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(value)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ xmean, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ xmedian, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}

\CommentTok{\#plot mean and median on the pineQ discharge histogram}
\NormalTok{PineP }\OtherTok{\textless{}{-}}\NormalTok{ pineQ }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(cfs)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ pineMean, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ pineMedian, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}

\NormalTok{Ex }\SpecialCharTok{/}\NormalTok{ PineP  }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-46-1.pdf}

\hypertarget{so-whats-a-weighted-average}{%
\subsection{So what's a weighted average?}\label{so-whats-a-weighted-average}}

When you compute a standard mean or median, you are giving equal weight to each measurement. Adding up all the values in a sample and dividing by the number of samples is the same as multiplying each value by 1/\# of samples. For instance if you had ten samples, to calculate the mean you would add them up and divide by 10. This is the same as multiplying each value by 1/10 and then adding them up. Each value is equally weighted at 1/10.

There are certain situations in which this is not the ideal way to calculate an average. A common one in hydrology is that you have samples that are supposed to represent different portions of an area. One sample may be taken to measure a forest type that takes up 100 ha of a watershed while another sample represents a forest type that only takes up 4 ha. You may not want to simply average those values!

Another example is precipitation gages. In the image below, you see there are 5 rain gages. To get a precipitation number for the watershed, we could just average them, or we could assume they represent an area of the watershed and then weight their values by the area they represent. One method of designating the areas is by using Theissen polygons (the middle watershed). Another method of weighting is isohyetal contours, but we won't worry about that for now!

In the weighted situation, we find the average by multiplying each precipitation values by the proportion of the watershed it represents, shown by the Thiessen polygons, and then add them all together. Let's do an example.

\includegraphics{images/theissen.png}source: \url{https://edx.hydrolearn.org/assets/courseware/v1/e5dc65098f1e8c5faacae0e171e28ccf/asset-v1:HydroLearn+HydroLearn401+2019_S2+type@asset+block/l2_image004.png}

The precip values for the watershed above are 4.5, 5.5, 5.8, 4.7, and 3.0

We will assume the proportions of the watershed that each gauge represents are 0.20, 0.15, 0.40, 0.15, 0.10, respectively (or 20\%, 15\%, 40\%, 15\%, 10\%)

Write some code to compute the regular mean precip from the values, and then the weighted mean.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{precip }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{4.5}\NormalTok{, }\FloatTok{5.5}\NormalTok{, }\FloatTok{5.8}\NormalTok{, }\FloatTok{4.7}\NormalTok{, }\FloatTok{3.0}\NormalTok{)}
\NormalTok{weights }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.15}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.15}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}

\FunctionTok{mean}\NormalTok{(precip)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(precip }\SpecialCharTok{*}\NormalTok{ weights)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5.05
\end{verbatim}

\hypertarget{measures-of-variability}{%
\section{Measures of variability}\label{measures-of-variability}}

Measures of variability allow us to measure the width of our sample data histogram or pdf. If all the values in our sample are close together, we would have small measures of variability, and a pointy pdf/histogram. If they vary more, we would have larger measures of variability and a broad pdf/histogram.

We will explore four measures of variability:

\hypertarget{variance}{%
\subsubsection{Variance:}\label{variance}}

Sum of the squared difference of each value from the mean divided by the number of samples minus 1. var()

\href{https://pubs.usgs.gov/tm/04/a03/tm4a3.pdf}{\includegraphics{images/Screen Shot 2021-01-25 at 10.29.45 AM.png}}

\hypertarget{standard-deviation}{%
\subsubsection{Standard deviation:}\label{standard-deviation}}

The square root of the variance sd()

**Both variance and standard deviation are sensitive to outliers.

\hypertarget{cv-coefficient-of-variation}{%
\subsubsection{CV: Coefficient of Variation}\label{cv-coefficient-of-variation}}

is simply the standard deviation divided by the mean of the data. Because you divide by the mean, CV is dimensionless. This allows you to use it to compare the variation in samples with very different magnitudes.

\hypertarget{iqr-interquartile-range}{%
\subsubsection{IQR: Interquartile Range}\label{iqr-interquartile-range}}

is resistant to outliers because it works like a median. It measures the range of the middle 50\% of the data in your distribution. So the IQR is the difference between the value between the 75th and 25th percentiles of your data, where the 75th percentile means 75\% of the data is BELOW that value and the 25th percentile means 25\% is below that value. Using the same vocabulary, the median is the same as the 50th percentile of the data.

If you ask R for the QUANTILES of your sample data, it will give you the values at which 0\%, 25\%, 50\%, 75\%, and 100\% of the data are below. These are the 1,2,3,4, and 5th quantiles. Therefore, the IQR is the difference between the 4th and 2nd quantile.

Okay, code time.

First, let's explore how changing the variability of a distribution changes the shape of it's distribution. Create a plot a random normal distribution using rnorm() and set sd to different numbers. Make the mean of the distribution 0, the sample size 300, and the standard deviation 1 to start. Then increase the standard deviation incrementally to 10 and see what happens. Make the limits of the x axis on the plot -30 to 30.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rnorm}\NormalTok{(}\DecValTok{300}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ as\_tibble }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(value))}\SpecialCharTok{+}
  \FunctionTok{stat\_density}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{30}\NormalTok{,}\DecValTok{30}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-48-1.pdf}

Now let's calculate the standard deviation, variance, coefficient of variation, and IQR of the Pine discharge data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#standard deviation}
\FunctionTok{sd}\NormalTok{(pineQ}\SpecialCharTok{$}\NormalTok{cfs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 84.47625
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#variance}
\FunctionTok{var}\NormalTok{(pineQ}\SpecialCharTok{$}\NormalTok{cfs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7136.237
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#coefficient of variation}
\FunctionTok{sd}\NormalTok{(pineQ}\SpecialCharTok{$}\NormalTok{cfs)}\SpecialCharTok{/}\FunctionTok{mean}\NormalTok{(pineQ}\SpecialCharTok{$}\NormalTok{cfs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.800221
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#IQR using the IQR funciton}
\FunctionTok{IQR}\NormalTok{(pineQ}\SpecialCharTok{$}\NormalTok{cfs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8.1325
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#IQR using the quantile function}
\NormalTok{quants }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(pineQ}\SpecialCharTok{$}\NormalTok{cfs)}
\NormalTok{quants[}\DecValTok{4}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ quants[}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    75% 
## 8.1325
\end{verbatim}

\hypertarget{what-about-how-lopsided-the-distribution-is}{%
\subsubsection{What about how lopsided the distribution is?}\label{what-about-how-lopsided-the-distribution-is}}

There are several ways to measure this as well, but we are just going to look at one: The Quartile skew. The quartile skew is the difference between the upper quartiles (50th-75th) and the lower quartiles (25th-50th) divided by the IQR (75th-25th).

\begin{figure}
\centering
\includegraphics{images/Screen Shot 2021-01-25 at 11.27.14 AM.png}
\caption{Quartile skew from USGS Stats Book linked above}
\end{figure}

Let's look at the quartile skew of the two distributions we've been measuring. Calculate it for the pineQ discharge data and the random normal distribution we generated.

Which one is more skewed?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{quantsP }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(pineQ}\SpecialCharTok{$}\NormalTok{cfs)}

\NormalTok{((quantsP[}\DecValTok{3}\NormalTok{]}\SpecialCharTok{{-}}\NormalTok{quantsP[}\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}}\NormalTok{ (quantsP[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ quantsP[}\DecValTok{1}\NormalTok{])) }\SpecialCharTok{/}\NormalTok{ quantsP[}\DecValTok{3}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ quantsP[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       50% 
## -4.837233
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{quantsX }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(ExNorm}\SpecialCharTok{$}\NormalTok{value)}

\NormalTok{((quantsX[}\DecValTok{3}\NormalTok{]}\SpecialCharTok{{-}}\NormalTok{quantsX[}\DecValTok{2}\NormalTok{]) }\SpecialCharTok{{-}}\NormalTok{ (quantsX[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ quantsX[}\DecValTok{1}\NormalTok{])) }\SpecialCharTok{/}\NormalTok{ quantsX[}\DecValTok{3}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ quantsX[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       50% 
## -2.413936
\end{verbatim}

\hypertarget{what-is-a-normal-distribution-and-how-can-we-determine-if-we-have-one}{%
\section{What is a normal distribution and how can we determine if we have one?}\label{what-is-a-normal-distribution-and-how-can-we-determine-if-we-have-one}}

The distribution we generated with rnorm() is a normal distribution. The distribution of pineQ discharge is not normal. Now that we've looked at different ways to characterize distributions, we have the vocabulary to describe why.

Normal distributions:

mean = median, half values to the right, half to the left

symmetric (not skewed)

Many statistical tests require that the distribution of the data you put into them is normally distributed. BE CAREFUL! There are also tests that use ranked data. Similar to how the median is resistant to outliers, these rank-based tests are resistant to non-normal data. Two popular ones are Kruskal-Wallis and Wilcoxon rank-sum.

But how far off can you be before you don't consider a distribution normal? Seems like a judgement call!

R to the rescue! There is a built in test for normality called shapiro.test(), which performs the Shapiro-Wilk test of normality. The hypothesis this test tests is ``The distribution is normal.'' So if this function returns a p-value less than 0.05, you reject that hypothesis and your function is NOT normal.

You can also make a quantile-quantile plot. A straight line on this plot indicates a normal distribution, a non-straight line indicates it is not normal.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{shapiro.test}\NormalTok{(pineQ}\SpecialCharTok{$}\NormalTok{cfs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  pineQ$cfs
## W = 0.27155, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qqnorm}\NormalTok{(pineQ}\SpecialCharTok{$}\NormalTok{cfs)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-51-1.pdf}

\hypertarget{statsactivity}{%
\chapter{Intro Stats Activity}\label{statsactivity}}

Address each of the questions in the code chunk below and/or by typing outside the chunk (for written answers).

\hypertarget{load-the-tidyverse-and-patchwork-libraries-and-read-in-the-flashy-and-pine-datasets.}{%
\section{1. Load the tidyverse and patchwork libraries and read in the Flashy and Pine datasets.}\label{load-the-tidyverse-and-patchwork-libraries-and-read-in-the-flashy-and-pine-datasets.}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(patchwork)}

\NormalTok{flashy }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"FLashy\_Dat\_Subset.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## -- Column specification --------------------------------------------------------
## cols(
##   .default = col_double(),
##   STANAME = col_character(),
##   STATE = col_character(),
##   CLASS = col_character(),
##   AGGECOREGION = col_character()
## )
## i Use `spec()` for the full column specifications.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SNP }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"PINE\_NFDR\_Jan{-}Mar\_2010.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## -- Column specification --------------------------------------------------------
## cols(
##   StationID = col_character(),
##   cfs = col_double(),
##   surrogate = col_character(),
##   datetime = col_datetime(format = ""),
##   year = col_double(),
##   quarter = col_double(),
##   month = col_double(),
##   day = col_double()
## )
\end{verbatim}

\hypertarget{using-the-flashy-dataset-make-a-pdf-of-the-average-basin-rainfall-pptavg_basin-for-the-northeast-aggecoregion.-on-that-pdf-add-vertical-lines-showing-the-mean-median-standard-deviation-and-iqr.-make-each-a-different-color-and-note-which-is-which-in-a-typed-answer-below-this-question.-or-if-you-want-an-extra-challenged-make-a-custom-legend-that-shows-this}{%
\section{2. Using the flashy dataset, make a pdf of the average basin rainfall (PPTAVG\_BASIN) for the NorthEast AGGECOREGION. On that pdf, add vertical lines showing the mean, median, standard deviation, and IQR. Make each a different color and note which is which in a typed answer below this question. (or if you want an extra challenged, make a custom legend that shows this)}\label{using-the-flashy-dataset-make-a-pdf-of-the-average-basin-rainfall-pptavg_basin-for-the-northeast-aggecoregion.-on-that-pdf-add-vertical-lines-showing-the-mean-median-standard-deviation-and-iqr.-make-each-a-different-color-and-note-which-is-which-in-a-typed-answer-below-this-question.-or-if-you-want-an-extra-challenged-make-a-custom-legend-that-shows-this}}

\hypertarget{perform-a-shapiro-wilk-test-for-normality-on-the-data-from-question-2.-using-the-results-from-that-test-and-the-plot-and-stats-from-question-2-discuss-whether-or-not-the-distribution-is-normal.}{%
\section{3. Perform a Shapiro-Wilk test for normality on the data from question 2. Using the results from that test and the plot and stats from question 2, discuss whether or not the distribution is normal.}\label{perform-a-shapiro-wilk-test-for-normality-on-the-data-from-question-2.-using-the-results-from-that-test-and-the-plot-and-stats-from-question-2-discuss-whether-or-not-the-distribution-is-normal.}}

\hypertarget{make-a-plot-that-shows-the-distribution-of-the-data-from-the-pine-watershed-and-the-nfdr-watershed-two-pdfs-on-the-same-plot.-log-the-x-axis.}{%
\section{4. Make a plot that shows the distribution of the data from the PINE watershed and the NFDR watershed (two pdfs on the same plot). Log the x axis.}\label{make-a-plot-that-shows-the-distribution-of-the-data-from-the-pine-watershed-and-the-nfdr-watershed-two-pdfs-on-the-same-plot.-log-the-x-axis.}}

\hypertarget{you-want-to-compare-how-variable-the-discharge-is-in-each-of-the-watersheds-in-question-4.-which-measure-of-spread-would-you-use-and-why-if-you-wanted-to-measure-the-central-tendency-which-measure-would-you-use-and-why}{%
\section{5. You want to compare how variable the discharge is in each of the watersheds in question 4. Which measure of spread would you use and why? If you wanted to measure the central tendency which measure would you use and why?}\label{you-want-to-compare-how-variable-the-discharge-is-in-each-of-the-watersheds-in-question-4.-which-measure-of-spread-would-you-use-and-why-if-you-wanted-to-measure-the-central-tendency-which-measure-would-you-use-and-why}}

\hypertarget{compute-3-measures-of-spread-and-2-measures-of-central-tendency-for-the-pine-and-nfdr-watershed.-hint-use-group_by-and-summarize-be-sure-your-code-outputs-the-result.-which-watershed-has-higher-flow-which-one-has-more-variable-flow-how-do-you-know}{%
\section{6. Compute 3 measures of spread and 2 measures of central tendency for the PINE and NFDR watershed. (hint: use group\_by() and summarize()) Be sure your code outputs the result. Which watershed has higher flow? Which one has more variable flow? How do you know?}\label{compute-3-measures-of-spread-and-2-measures-of-central-tendency-for-the-pine-and-nfdr-watershed.-hint-use-group_by-and-summarize-be-sure-your-code-outputs-the-result.-which-watershed-has-higher-flow-which-one-has-more-variable-flow-how-do-you-know}}

\hypertarget{getdata}{%
\chapter{Joins, Pivots, and USGS dataRetrieval}\label{getdata}}

Readings: Introduction to the dataRetrieval package \url{https://cran.r-project.org/web/packages/dataRetrieval/vignettes/dataRetrieval.html}

Chapter 12 \& 13 of R for Data Science \url{https://r4ds.had.co.nz/tidy-data.html}

\hypertarget{goals-for-today}{%
\section{Goals for today}\label{goals-for-today}}

\hypertarget{get-familiar-with-the-dataretrieval-package}{%
\subsection{1. Get familiar with the dataRetrieval package}\label{get-familiar-with-the-dataretrieval-package}}

\hypertarget{learn-about-long-vs.-wide-data-and-how-to-change-between-them}{%
\subsection{2. Learn about long vs.~wide data and how to change between them}\label{learn-about-long-vs.-wide-data-and-how-to-change-between-them}}

\hypertarget{brief-intro-to-joins}{%
\subsection{3. Brief intro to joins}\label{brief-intro-to-joins}}

\hypertarget{prep-question-how-would-you-get-data-from-the-usgs-non-r}{%
\subsection{Prep question: How would you get data from the USGS (non-R)?}\label{prep-question-how-would-you-get-data-from-the-usgs-non-r}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{install-the-dataretrieval-package.-load-it-and-the-tidyverse.}{%
\section{Install the dataRetrieval package. Load it and the tidyverse.}\label{install-the-dataretrieval-package.-load-it-and-the-tidyverse.}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#install.packages("dataRetrieval")}
\FunctionTok{library}\NormalTok{(dataRetrieval)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(lubridate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'lubridate' was built under R version 3.6.2
\end{verbatim}

\hypertarget{exploring-what-dataretrieval-can-do.}{%
\section{Exploring what dataRetrieval can do.}\label{exploring-what-dataretrieval-can-do.}}

Think about the dataRetrieval as a way to interact with same public data you can access through waterdata.usgs.gov but without having to click on buttons and search around. It makes getting data or doing analyses with USGS data much more reproducible and fast!

To explore a few of the capabilities (NOT ALL!!) we will start with the USGS gage on the New River at Radford. The gage number is 03171000.

The documentation for the package is extremely helpful: \url{https://cran.r-project.org/web/packages/dataRetrieval/vignettes/dataRetrieval.html}

I always have to look up how to do things because the package is very specialized! This is the case with most website APIs, in my experience. It's a good argument for getting good at navigating package documentation! Basically you just look through and try to piece together the recipe for what you want to do using the examples they give in the document.

First, let's get information about the site using the readNWISsite() and whatNWISdata() functions. Try each out and see what they tell you.

Remember, all the parameter codes and site names get passed to dataRetrieval functions as characters, ao they must be in quotes.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#important: note the site number gets input as a character}
\NormalTok{site }\OtherTok{\textless{}{-}} \StringTok{"03171000"}

\CommentTok{\#Information about the site}
\NormalTok{siteinfo }\OtherTok{\textless{}{-}} \FunctionTok{readNWISsite}\NormalTok{(site)}

\CommentTok{\#What data is available for the site?}
\CommentTok{\#Daily values, mean values}
\NormalTok{dataAvailable }\OtherTok{\textless{}{-}} \FunctionTok{whatNWISdata}\NormalTok{(}\AttributeTok{siteNumber =}\NormalTok{ site, }\AttributeTok{service =} \StringTok{"dv"}\NormalTok{, }\AttributeTok{statCd =} \StringTok{"00003"}\NormalTok{)}

\NormalTok{dataAvailable}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   agency_cd  site_no               station_nm site_tp_cd dec_lat_va dec_long_va
## 2      USGS 03171000 NEW RIVER AT RADFORD, VA         ST   37.14179   -80.56922
## 3      USGS 03171000 NEW RIVER AT RADFORD, VA         ST   37.14179   -80.56922
## 4      USGS 03171000 NEW RIVER AT RADFORD, VA         ST   37.14179   -80.56922
##   coord_acy_cd dec_coord_datum_cd   alt_va alt_acy_va alt_datum_cd   huc_cd
## 2            U              NAD83  1711.99       0.13       NAVD88 05050001
## 3            U              NAD83  1711.99       0.13       NAVD88 05050001
## 4            U              NAD83  1711.99       0.13       NAVD88 05050001
##   data_type_cd parm_cd stat_cd  ts_id loc_web_ds medium_grp_cd parm_grp_cd
## 2           dv   00010   00003 241564         NA           wat        <NA>
## 3           dv   00060   00003 145684         NA           wat        <NA>
## 4           dv   00095   00003 145685         NA           wat        <NA>
##    srs_id access_cd begin_date   end_date count_nu
## 2 1645597         0 2006-12-20 2009-03-18      704
## 3 1645423         0 1907-10-01 2021-02-22    32652
## 4 1646694         0 2006-12-20 2008-09-29      534
\end{verbatim}

When we look at what whatNWISdata returns, we see it gives us parameter codes, but doesn't tell us what they mean. This is a common attribute of databases: you use a common identifier but then have the full information in a lookup file. In this case, the look-up information telling us what the parameter codes mean is in ``parameterCdFile'' which loads with the dataRetrieval package.

So, you could look at that and see what the parameters mean.

OR We could have R do it and add a column that tells us what the parameters mean. Enter JOINS!

Joins allow us to combine the data from two different data sets that have a column in common. At its most basic, a join looks for a matching row with the same key in both datasets (for example, a USGS gage number) and then combines the rows. So now you have all the data from both sets, matched on the key.

But you have to make some decisions: what if a key value exists in one set but not the other? Do you just drop that observation? Do you add an NA? Let's look at the different options.

Take for example the two data sets, FlowTable and SizeTable. The SiteName values are the key values and the MeanFlow and WSsize values are the data.

\begin{figure}
\centering
\includegraphics[width=4.16667in,height=\textheight]{images/joinsetup.png}
\caption{Join Setup}
\end{figure}

Note River1 and River2 match up, but River3 and River5 only exist in one data set or the other.

The first way to deal with this is an inner join: inner\_join() In an inner join, you only keep records that match. So the rows for River3 and River5 will be dropped because there is no corresponding data in the other set. See below:

\begin{figure}
\centering
\includegraphics{images/innerjoin.png}
\caption{Inner Join}
\end{figure}

But what if you don't want to lose the values in one or the other or both?!

For instance, let's say you have a bunch of discharge data for a stream, and then chemistry grab samples. You want to join the chemistry to the discharge based on the dates and times they were taken. But when you do this, you don't want to delete all the discharge data where there is no chemistry! We need another option. Enter OUTER JOINS

LEFT JOIN, left\_join(): Preserves all values from the LEFT data set, and pastes on the matching ones from the right. This creates NAs where there is a value on the left but not the right. (this is what you'd want to do in the discharge - chemistry example above)

\begin{figure}
\centering
\includegraphics{images/leftjoin1.png}
\caption{Left Join}
\end{figure}

RIGHT JOIN, right\_join(): Preserves all values from the RIGHT data set, and pastes on the matching ones from the left. This creates NAs where there is a values on the right but not the left.

\begin{figure}
\centering
\includegraphics{images/rightjoin.png}
\caption{Right Join}
\end{figure}

FULL JOIN, full\_join(): KEEP EVERYTHING! The hoarder of the joins. No matching record on the left? create an NA on the right! No matching value on the right? Create an NA on the left! NAs for everyone!

\begin{figure}
\centering
\includegraphics{images/fulljoin.png}
\caption{Full Join}
\end{figure}

When you do this in R, you use the functions identified in the descriptions with the following syntax:

\hypertarget{if-the-column-is-named-the-same-in-both-data-sets-xxx_joinleft_tibble-right_tibble-by-key_column}{%
\subsubsection{if the column is named the same in both data sets xxx\_join(left\_tibble, right\_tibble, by = ``key\_column'')}\label{if-the-column-is-named-the-same-in-both-data-sets-xxx_joinleft_tibble-right_tibble-by-key_column}}

\hypertarget{if-the-column-is-named-differently-in-both-data-sets-xxx_joinleft_tibble-right_tibble-by-cleft_key-right_key}{%
\subsubsection{if the column is named differently in both data sets xxx\_join(left\_tibble, right\_tibble, by = c(``left\_key'' = ``right\_key'')}\label{if-the-column-is-named-differently-in-both-data-sets-xxx_joinleft_tibble-right_tibble-by-cleft_key-right_key}}

\begin{figure}
\centering
\includegraphics{images/leftjoin2.png}
\caption{Left Join Differing Col Names}
\end{figure}

Note in both of the above, when you specify which column to use as ``by'' you have to put it in quotes.

So in the chunk below let's get add information about the parameters in dataAvailable by joining it with the key file: parameterCdFile. The column with the parameter codes is called parm\_cd in dataAvailable and parameter\_cd in parameterCdFile

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dataAvailable }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(dataAvailable, parameterCdFile, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"parm\_cd"} \OtherTok{=} \StringTok{"parameter\_cd"}\NormalTok{))}

\NormalTok{dataAvailable}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   agency_cd  site_no               station_nm site_tp_cd dec_lat_va dec_long_va
## 1      USGS 03171000 NEW RIVER AT RADFORD, VA         ST   37.14179   -80.56922
## 2      USGS 03171000 NEW RIVER AT RADFORD, VA         ST   37.14179   -80.56922
## 3      USGS 03171000 NEW RIVER AT RADFORD, VA         ST   37.14179   -80.56922
##   coord_acy_cd dec_coord_datum_cd   alt_va alt_acy_va alt_datum_cd   huc_cd
## 1            U              NAD83  1711.99       0.13       NAVD88 05050001
## 2            U              NAD83  1711.99       0.13       NAVD88 05050001
## 3            U              NAD83  1711.99       0.13       NAVD88 05050001
##   data_type_cd parm_cd stat_cd  ts_id loc_web_ds medium_grp_cd parm_grp_cd
## 1           dv   00010   00003 241564         NA           wat        <NA>
## 2           dv   00060   00003 145684         NA           wat        <NA>
## 3           dv   00095   00003 145685         NA           wat        <NA>
##    srs_id access_cd begin_date   end_date count_nu parameter_group_nm
## 1 1645597         0 2006-12-20 2009-03-18      704           Physical
## 2 1645423         0 1907-10-01 2021-02-22    32652           Physical
## 3 1646694         0 2006-12-20 2008-09-29      534           Physical
##                                                                                 parameter_nm
## 1                                                        Temperature, water, degrees Celsius
## 2                                                           Discharge, cubic feet per second
## 3 Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius
##   casrn                  srsname parameter_units
## 1  <NA>       Temperature, water           deg C
## 2  <NA> Stream flow, mean. daily           ft3/s
## 3  <NA>     Specific conductance      uS/cm @25C
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#that made a lot of columns, let\textquotesingle{}s clean it up}
\NormalTok{dataAvailClean }\OtherTok{\textless{}{-}}\NormalTok{ dataAvailable }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(site\_no, }
\NormalTok{                                           station\_nm,}
\NormalTok{                                           parm\_cd, }
\NormalTok{                                           srsname, }
\NormalTok{                                           parameter\_units,}
\NormalTok{                                           begin\_date, }
\NormalTok{                                           end\_date)}

\NormalTok{dataAvailClean}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    site_no               station_nm parm_cd                  srsname
## 1 03171000 NEW RIVER AT RADFORD, VA   00010       Temperature, water
## 2 03171000 NEW RIVER AT RADFORD, VA   00060 Stream flow, mean. daily
## 3 03171000 NEW RIVER AT RADFORD, VA   00095     Specific conductance
##   parameter_units begin_date   end_date
## 1           deg C 2006-12-20 2009-03-18
## 2           ft3/s 1907-10-01 2021-02-22
## 3      uS/cm @25C 2006-12-20 2008-09-29
\end{verbatim}

\hypertarget{so-how-do-you-find-the-site-ids-for-downloading-data}{%
\section{So how do you find the site ids for downloading data?}\label{so-how-do-you-find-the-site-ids-for-downloading-data}}

You can find sites via map and just enter the id like we did in the chunks above: \url{https://maps.waterdata.usgs.gov/mapper/index.html}

Below we will look at two other ways to get sites: using a bounding box of a geographic region, or search terms like State and drainage area

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#find sites in a bounding box}
\CommentTok{\#coords of bottom left, top right}
\NormalTok{swva }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{81.36}\NormalTok{, }\FloatTok{36.72}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{80.27}\NormalTok{, }\FloatTok{37.32}\NormalTok{)}

\CommentTok{\#get sites in this bounding box that have daily water temperature and discharge}
\NormalTok{swva\_sites }\OtherTok{\textless{}{-}} \FunctionTok{whatNWISsites}\NormalTok{(}\AttributeTok{bBox =}\NormalTok{ swva, }
                            \AttributeTok{parameterCd =} \FunctionTok{c}\NormalTok{(}\StringTok{"00060"}\NormalTok{, }\StringTok{"00010"}\NormalTok{), }
                            \AttributeTok{hasDataTypeCd =} \StringTok{"dv"}\NormalTok{)}

\NormalTok{swva\_sites}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    agency_cd  site_no                                      station_nm
## 1       USGS 03473500             M F HOLSTON RIVER AT GROSECLOSE, VA
## 2       USGS 03175140         WEST FORK COVE CREEK NEAR BLUEFIELD, VA
## 3       USGS 03177710              BLUESTONE RIVER AT FALLS MILLS, VA
## 4       USGS 03177700                BLUESTONE RIVER AT BLUEFIELD, VA
## 5       USGS 03166000                  CRIPPLE CREEK NEAR IVANHOE, VA
## 6       USGS 03164500                      NEW RIVER NEAR GRAYSON, VA
## 7       USGS 03165500                        NEW RIVER AT IVANHOE, VA
## 8       USGS 03166880  WEST SP AT NAT FISH HAT NEAR GRAHAMS FORGE, VA
## 9       USGS 03166800                GLADE CREEK AT GRAHAMS FORGE, VA
## 10      USGS 03166900 BOILING SP AT NAT FISH HAT NR GRAHAMS FORGE, VA
## 11      USGS 03167000                 REED CREEK AT GRAHAMS FORGE, VA
## 12      USGS 03175500                     WOLF CREEK NEAR NARROWS, VA
## 13      USGS 03168500                       PEAK CREEK AT PULASKI, VA
## 14      USGS 03168000                      NEW RIVER AT ALLISONIA, VA
## 15      USGS 03167500        BIG REED ISLAND CREEK NEAR ALLISONIA, VA
## 16      USGS 03172500              WALKER CREEK AT STAFFORDSVILLE, VA
## 17      USGS 03173000                        WALKER CREEK AT BANE, VA
## 18      USGS 03171500                      NEW RIVER AT EGGLESTON, VA
## 19      USGS 03171000                        NEW RIVER AT RADFORD, VA
## 20      USGS 03170000                 LITTLE RIVER AT GRAYSONTOWN, VA
## 21      USGS 03169500             LITTLE RIVER NEAR COPPER VALLEY, VA
##    site_tp_cd dec_lat_va dec_long_va colocated           queryTime
## 1          ST   36.88873   -81.34733     FALSE 2021-02-23 07:56:26
## 2          ST   37.18428   -81.32982     FALSE 2021-02-23 07:56:26
## 3          ST   37.27151   -81.30482     FALSE 2021-02-23 07:56:26
## 4          ST   37.25595   -81.28177     FALSE 2021-02-23 07:56:26
## 5          ST   36.85984   -80.98036     FALSE 2021-02-23 07:56:26
## 6          ST   36.75985   -80.95619     FALSE 2021-02-23 07:56:26
## 7          ST   36.83485   -80.95258     FALSE 2021-02-23 07:56:26
## 8          SP   36.93429   -80.90313     FALSE 2021-02-23 07:56:26
## 9          ST   36.93095   -80.90036     FALSE 2021-02-23 07:56:26
## 10         SP   36.93068   -80.89619     FALSE 2021-02-23 07:56:26
## 11         ST   36.93901   -80.88730     FALSE 2021-02-23 07:56:26
## 12         ST   37.30568   -80.84980     FALSE 2021-02-23 07:56:26
## 13         ST   37.04734   -80.77618     FALSE 2021-02-23 07:56:26
## 14         ST   36.93762   -80.74563     FALSE 2021-02-23 07:56:26
## 15         ST   36.88901   -80.72757     FALSE 2021-02-23 07:56:26
## 16         ST   37.24179   -80.71090     FALSE 2021-02-23 07:56:26
## 17         ST   37.26818   -80.70951     FALSE 2021-02-23 07:56:26
## 18         ST   37.28957   -80.61673     FALSE 2021-02-23 07:56:26
## 19         ST   37.14179   -80.56922     FALSE 2021-02-23 07:56:26
## 20         ST   37.03763   -80.55672     FALSE 2021-02-23 07:56:26
## 21         ST   36.99652   -80.52144     FALSE 2021-02-23 07:56:26
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#find sites with other criteria, VA, less than 20 sqmi, other criteria can be used..}
\CommentTok{\#check out the CRAN documentation}
\NormalTok{smallVA }\OtherTok{\textless{}{-}} \FunctionTok{readNWISdata}\NormalTok{(}\AttributeTok{service =} \StringTok{"dv"}\NormalTok{,}
                           \AttributeTok{stateCd =} \StringTok{"VA"}\NormalTok{,}
                           \AttributeTok{parameterCd =} \StringTok{"00060"}\NormalTok{,}
                           \AttributeTok{drainAreaMax =} \StringTok{"20"}\NormalTok{,}
                           \AttributeTok{statCd =} \StringTok{"00003"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{ok-lets-download-some-data}{%
\section{OK let's download some data!}\label{ok-lets-download-some-data}}

We are going to use readNWISdv(), which downloads daily values.

We will tell it which sites to download, which parameters to download, and then what time period to download.

siteNumber gets the sites we want to download, USGS site numbers, as a character. We will use the swva\_sites data we generated (yep, you can download multiple sites at once!)

startDate and endDate get the\ldots. start and end dates. IMPORTANT: These must be in YYY-MM-DD format, but you don't have to tell R they are dates before you give them to the function, it'll do that for you.

parameterCd get the parameters you want to download. We want water temperature and discharge, which are ``00060'' and ``00010'', respectively.

Once we have the data, the column names correspond to the keys that identify them, for example, discharge will be 00060 something something. Fortunately the dataRetrieval package also provides ``renameNWISColumns()'' which translates these into words, making them more easily understood by humans. We can pipe the results of our download to that function after we get the data to make the column names easier to understand.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{start }\OtherTok{\textless{}{-}} \StringTok{"2006{-}10{-}01"}
\NormalTok{end }\OtherTok{\textless{}{-}} \StringTok{"2008{-}09{-}30"}
\NormalTok{params }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"00010"}\NormalTok{, }\StringTok{"00060"}\NormalTok{)}

\NormalTok{swva\_dat }\OtherTok{\textless{}{-}} \FunctionTok{readNWISdv}\NormalTok{(}\AttributeTok{siteNumber =}\NormalTok{ swva\_sites}\SpecialCharTok{$}\NormalTok{site\_no, }
                       \AttributeTok{parameterCd =}\NormalTok{ params, }
                       \AttributeTok{startDate =}\NormalTok{ start, }
                       \AttributeTok{endDate =}\NormalTok{ end) }\SpecialCharTok{\%\textgreater{}\%} 
            \FunctionTok{renameNWISColumns}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Let's plot the water temperature data as a line and control the color of the lines with the different sites.

What could be better about this plot?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{swva\_dat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Date, }\AttributeTok{y =}\NormalTok{ Wtemp, }\AttributeTok{color =}\NormalTok{ site\_no)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 2218 row(s) containing missing values (geom_path).
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-61-1.pdf}

We can add site names with\ldots.More joins! Our swva\_sites data has the names of the sites in human-friendly language. The column in the downloaded data and in the swva\_sites data is called ``site\_no'' so we just give that to the ``by'' argument. Perform a left join to add the names of the sites to the data.

Then use select to remove some of the unnecessary columns.

Then make the plot and then snazz it up with labels and a non-junky theme.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{swva\_dat\_clean }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(swva\_dat, swva\_sites, }\AttributeTok{by =} \StringTok{"site\_no"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(station\_nm, site\_no, Date, Flow, Wtemp, dec\_lat\_va, dec\_long\_va)}

\NormalTok{swva\_dat\_clean }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Date, }\AttributeTok{y =}\NormalTok{ Wtemp, }\AttributeTok{color =}\NormalTok{ station\_nm)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Water temperature (deg C)"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\FunctionTok{element\_blank}\NormalTok{())}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{color =} \StringTok{"Gage Site"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 2218 row(s) containing missing values (geom_path).
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-62-1.pdf}

\hypertarget{pivoting-wide-and-long-data}{%
\section{Pivoting: wide and long data}\label{pivoting-wide-and-long-data}}

Okay, so with the data above: what would you do if you wanted to subtract the discharge or temperature of one gage from another on the same river: to compute rate of change between the two sites, for instance.

You could split them into two objects, then join based on date?

Or\ldots now hear me out\ldots{} you could PIVOT them.

A two-dimensional object can be either long or wide. Each has it's advantages.

\hypertarget{long}{%
\subsection{LONG}\label{long}}

Each observation has it's own row. In the first image below, the table on the left is long because each measure of ``cases'' has it's own row. It's year and country are identified by a second column, and the values in that column repeat a lot. (Look at country and year in the table on the left)

\hypertarget{wide}{%
\subsection{WIDE}\label{wide}}

Observations of different things have their own columns. In the second image below, notice in the right hand table there is a ``cases'' and ``population'' column rather than an identifier in a separate column like in the table on the left.

\hypertarget{why}{%
\subsection{Why?}\label{why}}

Long and wide data are more efficient for different things. Think about plotting a data set with 10 stream gages. If they are in a long format, you can just add color = Gage to your ggplot aes(). If they are in a wide format, meaning each gage has it's own column, you'd have to write a new geom for EACH gage, because they're all in separate columns.

Now imagine you want to do some math to create new data: let's say cases divided by population in the second image below\ldots. How would you even do that using the data on the left? With the wide data on the right it is simply mutate(casesPERpop = cases / population).

Finally, which table is easier to read in TABLE format (not a plot) in each of the two images below? Wide data is much more fitting for tables.

\begin{figure}
\centering
\includegraphics{images/pivot_longer.png}
\caption{Pivoting to a longer format}
\end{figure}

\begin{figure}
\centering
\includegraphics{images/pivot_wider.png}
\caption{Pivoting to a wider format}
\end{figure}

dplyr, part of the tidyverse, has functions to convert data between wide and long data. I have to look up the syntax every single time I use them. But they are VERY useful.

Back to our original question: I want to subtract the flow at Ivanhoe from the flow at Radford on the new river to see how much flow increases between the two sites through time.

To do this I am going to use pivot\_wider() to give Ivanhoe and Radford discharges their own column.

First, we will use select to trim the data to just what we need, then call pivot\_wider telling it which data to use for the new column names (names\_from = station\_nm) and what values we want to pivot into the data under those columns (values\_from = Flow).

Then, subtract the two and make a plot!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Pivot so we can compute diffs between one river and others}

\NormalTok{swva\_wide }\OtherTok{\textless{}{-}}\NormalTok{ swva\_dat\_clean }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(station\_nm, Flow, Date) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from =}\NormalTok{ station\_nm, }\AttributeTok{values\_from =}\NormalTok{ Flow)}

\NormalTok{swva\_wide }\OtherTok{\textless{}{-}}\NormalTok{ swva\_wide }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Radford\_Ivanhoe =} \StringTok{\textasciigrave{}}\AttributeTok{NEW RIVER AT RADFORD, VA}\StringTok{\textasciigrave{}} \SpecialCharTok{{-}} \StringTok{\textasciigrave{}}\AttributeTok{NEW RIVER AT IVANHOE, VA}\StringTok{\textasciigrave{}}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(swva\_wide, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Date, }\AttributeTok{y =}\NormalTok{ Radford\_Ivanhoe))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Change in flow from Ivanhoe to Radford"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-63-1.pdf}

To further illustrate how to move between long and wide data and when to use them, let's grab some water quality data. This process will also review some of the other concepts from this topic.

In the chunk below we will look to see what sites have data for nitrate and chloride in our swva bounding box from above. We will them filter them to just stream sites (leave out groundwater and springs). And finally we will download the nitrate and chloride data for those sites.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Nitrate as nitrate and chloride}
\NormalTok{params }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"00940"}\NormalTok{, }\StringTok{"71851"}\NormalTok{)}

\CommentTok{\#what sites in our bounding box have cloride and nitrate}
\NormalTok{swva\_chem\_sites }\OtherTok{\textless{}{-}} \FunctionTok{whatNWISsites}\NormalTok{(}\AttributeTok{bBox =}\NormalTok{ swva, }
                            \AttributeTok{parameterCd =}\NormalTok{ params)}

\CommentTok{\#filte to just stream water}
\NormalTok{swva\_chem\_sites }\OtherTok{\textless{}{-}} \FunctionTok{filter}\NormalTok{(swva\_chem\_sites, site\_tp\_cd }\SpecialCharTok{==} \StringTok{"ST"}\NormalTok{)}

\NormalTok{wqdat }\OtherTok{\textless{}{-}} \FunctionTok{readNWISqw}\NormalTok{(}\AttributeTok{siteNumber =}\NormalTok{ swva\_chem\_sites}\SpecialCharTok{$}\NormalTok{site\_no, }
                    \AttributeTok{parameterCd =}\NormalTok{ params)}

\FunctionTok{comment}\NormalTok{(wqdat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1] "#"                                                                                                                                            
##   [2] "# File created on 2021-02-23 07:56:32 EST"                                                                                                    
##   [3] "#"                                                                                                                                            
##   [4] "# U.S. Geological Survey"                                                                                                                     
##   [5] "# "                                                                                                                                           
##   [6] "# This file contains selected water-quality data for stations in the National Water "                                                         
##   [7] "# Information System water-quality database.  Explanation of codes found in this file are "                                                   
##   [8] "# followed by the retrieved data. "                                                                                                           
##   [9] "#"                                                                                                                                            
##  [10] "# The data you have secured from the USGS NWISWeb database may include data that have "                                                       
##  [11] "# not received Director's approval and as such are provisional and subject to revision. "                                                     
##  [12] "# The data are released on the condition that neither the USGS nor the United States "                                                        
##  [13] "# Government may be held liable for any damages resulting from its authorized or "                                                            
##  [14] "# unauthorized use."                                                                                                                          
##  [15] "#"                                                                                                                                            
##  [16] "# To view additional data-quality attributes, output the results using these options:  "                                                      
##  [17] "# one result per row, expanded attributes.  Additional precautions are at:"                                                                   
##  [18] "# https://help.waterdata.usgs.gov/tutorials/water-quality-data/help-using-the-water-quality-data-retrieval-system#Data_retrievals_precautions"
##  [19] "#"                                                                                                                                            
##  [20] "#  agency_cd                  - Agency Code"                                                                                                  
##  [21] "#  site_no                    - USGS site number"                                                                                             
##  [22] "#  sample_dt                  - Begin date"                                                                                                   
##  [23] "#  sample_tm                  - Begin time"                                                                                                   
##  [24] "#  sample_end_dt              - End date"                                                                                                     
##  [25] "#  sample_end_tm              - End time"                                                                                                     
##  [26] "#  sample_start_time_datum_cd - Time datum"                                                                                                   
##  [27] "#  tm_datum_rlbty_cd          - Time datum reliability code"                                                                                  
##  [28] "#  coll_ent_cd                - Agency Collecting Sample Code"                                                                                
##  [29] "#  medium_cd                  - Sample Medium Code"                                                                                           
##  [30] "#  project_cd                 - Project code"                                                                                                 
##  [31] "#  aqfr_cd                    - Geologic unit code"                                                                                           
##  [32] "#  tu_id                      - Taxonomic unit code"                                                                                          
##  [33] "#  body_part_id               - Body part code"                                                                                               
##  [34] "#  hyd_cond_cd                - Hydrologic Cond Code"                                                                                         
##  [35] "#  samp_type_cd               - Sample Type Code"                                                                                             
##  [36] "#  hyd_event_cd               - Hydrologic Event Code"                                                                                        
##  [37] "#  sample_lab_cm_tx           - Message from lab"                                                                                             
##  [38] "#  parm_cd                    - Parameter code"                                                                                               
##  [39] "#  remark_cd                  - Remark code"                                                                                                  
##  [40] "#  result_va                  - Parameter value"                                                                                              
##  [41] "#  val_qual_tx                - Result value qualifier code"                                                                                  
##  [42] "#  meth_cd                    - Method code"                                                                                                  
##  [43] "#  dqi_cd                     - Data-quality indicator code"                                                                                  
##  [44] "#  rpt_lev_va                 - Reporting level"                                                                                              
##  [45] "#  rpt_lev_cd                 - Reporting level type"                                                                                         
##  [46] "#  lab_std_va                 - Lab standard deviation"                                                                                       
##  [47] "#  prep_set_no                - Prep set number"                                                                                              
##  [48] "#  prep_dt                    - Result prep date"                                                                                             
##  [49] "#  anl_set_no                 - Analysis set number"                                                                                          
##  [50] "#  anl_dt                     - Result analysis date"                                                                                         
##  [51] "#  result_lab_cm_tx           - Lab result comment"                                                                                           
##  [52] "#  anl_ent_cd                 - Analyzing entity code"                                                                                        
##  [53] "#"                                                                                                                                            
##  [54] "# The following parameters are included:"                                                                                                     
##  [55] "#  00940  - Chloride, water, filtered, milligrams per liter"                                                                                  
##  [56] "#  71851  - Nitrate, water, filtered, milligrams per liter as nitrate"                                                                        
##  [57] "#"                                                                                                                                            
##  [58] "# Description of sample_start_time_datum_cd:"                                                                                                 
##  [59] "# EST  - Eastern Standard Time"                                                                                                               
##  [60] "# EDT  - Eastern Daylight Time"                                                                                                               
##  [61] "#"                                                                                                                                            
##  [62] "# Description of tm_datum_rlbty_cd:"                                                                                                          
##  [63] "# K  - Known"                                                                                                                                 
##  [64] "# T  - Transferred"                                                                                                                           
##  [65] "#"                                                                                                                                            
##  [66] "# Description of coll_ent_cd and anl_ent_cd:"                                                                                                 
##  [67] "# USGS-WRD  - U.S. Geological Survey-Water Resources Discipline"                                                                              
##  [68] "# USGS-NYL  - USGS-NY WSC Low Ionic Strength Lab,Troy(formerly Albany)"                                                                       
##  [69] "#"                                                                                                                                            
##  [70] "# Description of medium_cd:"                                                                                                                  
##  [71] "# WS  - Surface water"                                                                                                                        
##  [72] "#"                                                                                                                                            
##  [73] "# Description of aqfr_cd:"                                                                                                                    
##  [74] "#"                                                                                                                                            
##  [75] "# Description of tu_id:"                                                                                                                      
##  [76] "# https://www.itis.gov/"                                                                                                                      
##  [77] "#"                                                                                                                                            
##  [78] "# Description of body_part_id:"                                                                                                               
##  [79] "#"                                                                                                                                            
##  [80] "# Description of hyd_cond_cd:"                                                                                                                
##  [81] "# 4  - Stable, low stage"                                                                                                                     
##  [82] "# 5  - Falling stage"                                                                                                                         
##  [83] "# 6  - Stable, high stage"                                                                                                                    
##  [84] "# 8  - Rising stage"                                                                                                                          
##  [85] "# 9  - Stable, normal stage"                                                                                                                  
##  [86] "# A  - Not determined"                                                                                                                        
##  [87] "#"                                                                                                                                            
##  [88] "# Description of samp_type_cd:"                                                                                                               
##  [89] "# 7  - Replicate"                                                                                                                             
##  [90] "# 9  - Regular"                                                                                                                               
##  [91] "#"                                                                                                                                            
##  [92] "# Description of hyd_event_cd:"                                                                                                               
##  [93] "# 9  - Routine sample"                                                                                                                        
##  [94] "#"                                                                                                                                            
##  [95] "# Description of remark_cd:"                                                                                                                  
##  [96] "#"                                                                                                                                            
##  [97] "# Description of val_qual_tx:"                                                                                                                
##  [98] "#"                                                                                                                                            
##  [99] "# Description of meth_cd:"                                                                                                                    
## [100] "# ALGOR  - Computation by NWIS algorithm"                                                                                                     
## [101] "# CL031  - Chloride, wf, ASF thiocyanate"                                                                                                     
## [102] "# IC022  - Anions, wf, IC"                                                                                                                    
## [103] "# IC034  - Anions, wf, IC (USGS-NYL)"                                                                                                         
## [104] "#"                                                                                                                                            
## [105] "# Description of dqi_cd:"                                                                                                                     
## [106] "# A  - Historical data"                                                                                                                       
## [107] "# R  - Reviewed and approved"                                                                                                                 
## [108] "#"                                                                                                                                            
## [109] "# Description of rpt_lev_cd:"                                                                                                                 
## [110] "# MRL  - Minimum reporting level"                                                                                                             
## [111] "#"                                                                                                                                            
## [112] "# Data for the following sites are included:"                                                                                                 
## [113] "#  USGS 03165500 NEW RIVER AT IVANHOE, VA"                                                                                                    
## [114] "#  USGS 03167000 REED CREEK AT GRAHAMS FORGE, VA"                                                                                             
## [115] "#  USGS 03167500 BIG REED ISLAND CREEK NEAR ALLISONIA, VA"                                                                                    
## [116] "#  USGS 03168000 NEW RIVER AT ALLISONIA, VA"                                                                                                  
## [117] "#  USGS 03168500 PEAK CREEK AT PULASKI, VA"                                                                                                   
## [118] "#  USGS 03170000 LITTLE RIVER AT GRAYSONTOWN, VA"                                                                                             
## [119] "#  USGS 03171000 NEW RIVER AT RADFORD, VA"                                                                                                    
## [120] "#  USGS 03171500 NEW RIVER AT EGGLESTON, VA"                                                                                                  
## [121] "#  USGS 03172500 WALKER CREEK AT STAFFORDSVILLE, VA"                                                                                          
## [122] "#  USGS 03173000 WALKER CREEK AT BANE, VA"                                                                                                    
## [123] "#  USGS 03175500 WOLF CREEK NEAR NARROWS, VA"                                                                                                 
## [124] "#  USGS 03473500 M F HOLSTON RIVER AT GROSECLOSE, VA"                                                                                         
## [125] "#  USGS 371852081031201 006.0 EAST RIVER NEAR ENGLESIDE, W. VA."                                                                              
## [126] "#  USGS 370853081003801 AT 23045 UNNAMED EPHEMERAL TRIB TO WALKER CREEK VA"                                                                   
## [127] "#  USGS 370941081005201 AT 23045.5 UNNAMED INTERMIT TRIB TO KIMBERLING CR"                                                                    
## [128] "#  USGS 370847081055101 AT 23046 KIMBERLING CREEK VA"                                                                                         
## [129] "#  USGS 371250080511401 AT 22014 DISMAL CREEK VA"                                                                                             
## [130] "#  USGS 370534081144701 AT 22013 HUNTING CAMP CREEK VA"                                                                                       
## [131] "#  USGS 370603081120801 AT 22013.5 LAUREL CR AT MOUTH OF LITTLE WOLF CR VA"                                                                   
## [132] "#"
\end{verbatim}

Now, let's clean things up a bit.

Join the parameter names from parameterCdFile and then join the site names from swva\_chem\_site. Then select just the columns we want, and finally filter the remaining data to just look at sites from the New River.

To illustrate the functionality of the data in this format, plot Chloride for each site, and then plot Chloride AND Nitrate, using the parameter name in facet\_wrap.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wqdat\_clean }\OtherTok{\textless{}{-}}\NormalTok{ wqdat }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{left\_join}\NormalTok{(parameterCdFile, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"parm\_cd"} \OtherTok{=} \StringTok{"parameter\_cd"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(swva\_chem\_sites, }\AttributeTok{by =} \StringTok{"site\_no"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(station\_nm, sample\_dt, sample\_tm, result\_va, srsname, parameter\_units) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(station\_nm, }\StringTok{"NEW RIVER"}\NormalTok{))}
  
\NormalTok{wqdat\_clean }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(srsname }\SpecialCharTok{==} \StringTok{"Chloride"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ sample\_dt, }\AttributeTok{y =}\NormalTok{ result\_va, }\AttributeTok{color =}\NormalTok{ station\_nm)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Chloride (mg/L)"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\FunctionTok{element\_blank}\NormalTok{())}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{color =} \StringTok{"Site"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-65-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wqdat\_clean }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ sample\_dt, }\AttributeTok{y =}\NormalTok{ result\_va, }\AttributeTok{color =}\NormalTok{ station\_nm)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\AttributeTok{facets =} \StringTok{"srsname"}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Concentration (mg/L)"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\FunctionTok{element\_blank}\NormalTok{())}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{color =} \StringTok{"Site"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-65-2.pdf}

Now let's say we want to calculate something with chloride and nitrate. We need to make the data wide so we have a nitrate column and a chloride column. Do that below. What goes into values\_from? what goes into names\_from?

Next, plot Chloride + Nitrate. Could you do this with the data in the previous format?

Finally, use pivot\_longer to transform the data back into a long format. Often you'll get data in a wide format and need to convert it to long, and we haven't tried that yet. The only argument you'll need to pass to pivot\_longer() in this case is to tell it what columns to turn into the new DATA column (using the cols = ) parameter.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#make wqdat\_clean wide}

\NormalTok{wqdat\_wide }\OtherTok{\textless{}{-}}\NormalTok{ wqdat\_clean }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{parameter\_units) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{values\_from =}\NormalTok{ result\_va, }\AttributeTok{names\_from =}\NormalTok{ srsname)}

\FunctionTok{ggplot}\NormalTok{(wqdat\_wide, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ sample\_dt, }\AttributeTok{y =}\NormalTok{ Chloride }\SpecialCharTok{+}\NormalTok{ Nitrate)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 106 rows containing missing values (geom_point).
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-66-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wqlonger }\OtherTok{\textless{}{-}}\NormalTok{ wqdat\_wide }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{c}\NormalTok{(}\StringTok{"Chloride"}\NormalTok{, }\StringTok{"Nitrate"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{joinpivotDR}{%
\chapter{Joins Pivots dataRetrieval Activity}\label{joinpivotDR}}

\hypertarget{load-the-tidyverse-dataretrieval-and-patchwork-packages.}{%
\subsection{Load the tidyverse, dataRetrieval, and patchwork packages.}\label{load-the-tidyverse-dataretrieval-and-patchwork-packages.}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(dataRetrieval)}
\FunctionTok{library}\NormalTok{(patchwork)}
\end{Highlighting}
\end{Shaded}

\hypertarget{using-readnwisqw-read-all-the-chloride-00940-data-for-the-new-river-at-radford-03171000.}{%
\subsection{1. Using readNWISqw(), read all the chloride (00940) data for the New River at Radford (03171000).}\label{using-readnwisqw-read-all-the-chloride-00940-data-for-the-new-river-at-radford-03171000.}}

\hypertarget{use-the-head-function-to-print-the-beginning-of-the-output-from-readnwisqw.}{%
\subsection{Use the head() function to print the beginning of the output from readNWISqw.}\label{use-the-head-function-to-print-the-beginning-of-the-output-from-readnwisqw.}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Chloride and Nitrate}
\NormalTok{param }\OtherTok{\textless{}{-}} \StringTok{"00940"}
\NormalTok{site }\OtherTok{\textless{}{-}} \StringTok{"03171000"}

\NormalTok{newriverWQ }\OtherTok{\textless{}{-}} \FunctionTok{readNWISqw}\NormalTok{(}\AttributeTok{siteNumber =}\NormalTok{ site, }
                       \AttributeTok{parameterCd =}\NormalTok{ param) }

\FunctionTok{head}\NormalTok{(newriverWQ)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   agency_cd  site_no  sample_dt sample_tm sample_end_dt sample_end_tm
## 1      USGS 03171000 2007-01-03     11:40            NA          <NA>
## 2      USGS 03171000 2007-02-27     11:25            NA          <NA>
## 3      USGS 03171000 2007-04-02     11:00            NA          <NA>
## 4      USGS 03171000 2007-05-22     10:00            NA          <NA>
## 5      USGS 03171000 2007-07-09     11:30            NA          <NA>
## 6      USGS 03171000 2007-08-20     13:20            NA          <NA>
##   sample_start_time_datum_cd tm_datum_rlbty_cd coll_ent_cd medium_cd project_cd
## 1                        EST                 K        <NA>        WS  248200201
## 2                        EST                 K        <NA>        WS  248200201
## 3                        EDT                 K        <NA>        WS  248200201
## 4                        EDT                 K        <NA>        WS  248200201
## 5                        EDT                 K        <NA>        WS  248200201
## 6                        EDT                 K        <NA>        WS  248200201
##   aqfr_cd tu_id body_part_id hyd_cond_cd samp_type_cd hyd_event_cd
## 1    <NA>  <NA>         <NA>           9            7            9
## 2    <NA>  <NA>         <NA>           9            9            9
## 3    <NA>  <NA>         <NA>           9            9            9
## 4    <NA>  <NA>         <NA>           9            9            9
## 5    <NA>  <NA>         <NA>           9            9            9
## 6    <NA>  <NA>         <NA>           9            9            9
##   sample_lab_cm_tx parm_cd remark_cd result_va val_qual_tx meth_cd dqi_cd
## 1             <NA>   00940      <NA>       6.1        <NA>    <NA>      R
## 2             <NA>   00940      <NA>       7.4        <NA>    <NA>      R
## 3             <NA>   00940      <NA>       7.1        <NA>    <NA>      R
## 4             <NA>   00940      <NA>       6.8        <NA>    <NA>      R
## 5             <NA>   00940      <NA>       6.7        <NA>    <NA>      R
## 6             <NA>   00940      <NA>       6.5        <NA>    <NA>      R
##   rpt_lev_va rpt_lev_cd lab_std_va prep_set_no prep_dt anl_set_no anl_dt
## 1         NA       <NA>         NA          NA      NA         NA     NA
## 2         NA       <NA>         NA          NA      NA         NA     NA
## 3         NA       <NA>         NA          NA      NA         NA     NA
## 4         NA       <NA>         NA          NA      NA         NA     NA
## 5         NA       <NA>         NA          NA      NA         NA     NA
## 6         NA       <NA>         NA          NA      NA         NA     NA
##   result_lab_cm_tx anl_ent_cd       startDateTime
## 1             <NA>       <NA> 2007-01-03 11:40:00
## 2             <NA>       <NA> 2007-02-27 11:25:00
## 3             <NA>       <NA> 2007-04-02 11:00:00
## 4             <NA>       <NA> 2007-05-22 10:00:00
## 5             <NA>       <NA> 2007-07-09 11:30:00
## 6             <NA>       <NA> 2007-08-20 13:20:00
\end{verbatim}

\hypertarget{using-the-readnwisdv-daily-values-function-download-discharge-00060-temperature-00003-and-specific-conductivity-00095-for-the-new-river-at-radford-from-2007-to-2009-regular-year.}{%
\subsection{2. Using the readNWISdv (daily values) function, download discharge (00060), temperature (00003), and specific conductivity (00095) for the New River at Radford from 2007 to 2009 (regular year).}\label{using-the-readnwisdv-daily-values-function-download-discharge-00060-temperature-00003-and-specific-conductivity-00095-for-the-new-river-at-radford-from-2007-to-2009-regular-year.}}

\hypertarget{use-renamenwiscolumns-to-rename-the-output-of-the-download.}{%
\subsection{Use renameNWIScolumns() to rename the output of the download.}\label{use-renamenwiscolumns-to-rename-the-output-of-the-download.}}

\hypertarget{use-head-to-show-the-beginning-of-the-results-of-your-download.}{%
\subsection{Use head() to show the beginning of the results of your download.}\label{use-head-to-show-the-beginning-of-the-results-of-your-download.}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{start }\OtherTok{\textless{}{-}} \StringTok{"2007{-}01{-}01"}
\NormalTok{end }\OtherTok{\textless{}{-}} \StringTok{"2009{-}01{-}01"}
\NormalTok{params }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"00060"}\NormalTok{, }\StringTok{"00003"}\NormalTok{,}\StringTok{"00095"}\NormalTok{)}

\NormalTok{newphys }\OtherTok{\textless{}{-}} \FunctionTok{readNWISdv}\NormalTok{(}\AttributeTok{siteNumber =}\NormalTok{ site, }
                       \AttributeTok{parameterCd =}\NormalTok{ params, }
                       \AttributeTok{startDate =}\NormalTok{ start, }
                       \AttributeTok{endDate =}\NormalTok{ end) }\SpecialCharTok{\%\textgreater{}\%} 
            \FunctionTok{renameNWISColumns}\NormalTok{()}

\FunctionTok{head}\NormalTok{(newphys)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   agency_cd  site_no       Date  Flow Flow_cd SpecCond SpecCond_cd
## 1      USGS 03171000 2007-01-01  8810       A      122           A
## 2      USGS 03171000 2007-01-02 13100       A      116           A
## 3      USGS 03171000 2007-01-03 10700       A       NA        <NA>
## 4      USGS 03171000 2007-01-04  8960       A       NA        <NA>
## 5      USGS 03171000 2007-01-05  5210       A       NA        <NA>
## 6      USGS 03171000 2007-01-06  4640       A       NA        <NA>
\end{verbatim}

\hypertarget{do-a-left-join-on-newphys-and-newriver-to-add-the-chloride-data-to-the-daily-discharge-temp-and-conductivity-data.-hint-you-will-join-on-the-date.}{%
\subsection{3. Do a left join on newphys and newriver to add the chloride data to the daily discharge, temp, and conductivity data. hint: you will join on the date.}\label{do-a-left-join-on-newphys-and-newriver-to-add-the-chloride-data-to-the-daily-discharge-temp-and-conductivity-data.-hint-you-will-join-on-the-date.}}

\hypertarget{preview-your-data-below-the-chunk-using-head}{%
\subsection{Preview your data below the chunk using head()}\label{preview-your-data-below-the-chunk-using-head}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newwqp }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(newphys, newriverWQ, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"Date"} \OtherTok{=} \StringTok{"sample\_dt"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{create-a-line-plot-of-date-x-and-flow-y.-create-a-scatter-plot-of-date-x-and-chloride-concentration-y.-put-the-graphs-on-top-of-each-other-using-the-patchwork-library.}{%
\subsection{4. Create a line plot of Date (x) and Flow (y). Create a scatter plot of Date (x) and chloride concentration (y). Put the graphs on top of each other using the patchwork library.}\label{create-a-line-plot-of-date-x-and-flow-y.-create-a-scatter-plot-of-date-x-and-chloride-concentration-y.-put-the-graphs-on-top-of-each-other-using-the-patchwork-library.}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{QP }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(newwqp, }\FunctionTok{aes}\NormalTok{(Date, Flow))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}

\NormalTok{WQP }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(newwqp, }\FunctionTok{aes}\NormalTok{(Date, result\_va))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}

\NormalTok{QP}\SpecialCharTok{/}\NormalTok{WQP}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 721 rows containing missing values (geom_point).
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-71-1.pdf}

\hypertarget{create-a-scatter-plot-of-specific-conductivity-y-and-chloride-x.-challenge-what-could-you-do-to-get-rid-of-the-warning-this-plot-generates-about-nas.}{%
\subsection{5. Create a scatter plot of Specific Conductivity (y) and Chloride (x). Challenge: what could you do to get rid of the warning this plot generates about NAs.}\label{create-a-scatter-plot-of-specific-conductivity-y-and-chloride-x.-challenge-what-could-you-do-to-get-rid-of-the-warning-this-plot-generates-about-nas.}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newwqp }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{drop\_na}\NormalTok{(SpecCond, result\_va) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ SpecCond, }\AttributeTok{y =}\NormalTok{ result\_va))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-72-1.pdf}

\hypertarget{read-in-the-gg-chem-subset-data-and-plot-mg_e1-x-vs-ca_e1-y-as-points.}{%
\subsection{6. Read in the GG chem subset data and plot Mg\_E1 (x) vs Ca\_E1 (y) as points.}\label{read-in-the-gg-chem-subset-data-and-plot-mg_e1-x-vs-ca_e1-y-as-points.}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subset }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"GG\_chem\_subest.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## -- Column specification --------------------------------------------------------
## cols(
##   SiteName = col_character(),
##   Ca_E1 = col_double(),
##   Na_E1 = col_double(),
##   Mg_E1 = col_double(),
##   Distance = col_double()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(subset, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Mg\_E1, }\AttributeTok{y =}\NormalTok{ Ca\_E1 ))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-73-1.pdf}

\hypertarget{we-want-to-look-at-concentrations-of-each-element-in-the-6-dataset-along-the-stream-distance-which-is-difficult-in-the-current-format.-pivot-the-data-into-a-long-format-the-data-from-ca-mg-and-na-_e1-columns-should-be-pivoted.}{%
\subsection{7. We want to look at concentrations of each element in the \#6 dataset along the stream (Distance), which is difficult in the current format. Pivot the data into a long format, the data from Ca, Mg, and Na \_E1 columns should be pivoted.}\label{we-want-to-look-at-concentrations-of-each-element-in-the-6-dataset-along-the-stream-distance-which-is-difficult-in-the-current-format.-pivot-the-data-into-a-long-format-the-data-from-ca-mg-and-na-_e1-columns-should-be-pivoted.}}

\hypertarget{make-line-plots-of-each-element-where-y-is-the-concentration-and-x-is-distance.-use-facet_wrap-to-create-a-separate-plot-for-each-element-and-use-the-scales-argument-of-facet_wrap-to-allow-each-plot-to-have-different-y-limits.}{%
\subsection{Make line plots of each element where y is the concentration and x is distance. Use facet\_wrap() to create a separate plot for each element and use the ``scales'' argument of facet\_wrap to allow each plot to have different y limits.}\label{make-line-plots-of-each-element-where-y-is-the-concentration-and-x-is-distance.-use-facet_wrap-to-create-a-separate-plot-for-each-element-and-use-the-scales-argument-of-facet_wrap-to-allow-each-plot-to-have-different-y-limits.}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wqlong }\OtherTok{\textless{}{-}}\NormalTok{ subset }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{c}\NormalTok{(Ca\_E1, Mg\_E1, Na\_E1))}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ wqlong, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Distance, }\AttributeTok{y =}\NormalTok{ value, }\AttributeTok{color =}\NormalTok{ name))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\AttributeTok{facets =} \StringTok{"name"}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{3}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-74-1.pdf}

\hypertarget{Summative1}{%
\chapter{Summative Activity 1}\label{Summative1}}

\hypertarget{instructions}{%
\subsection{Instructions}\label{instructions}}

Please read carefully!\\
You can use anything you want to help you perform the tasks below, but you CANNOT ask other people for help.

Write your code in the provided code chunks and answer any questions by typing outside the chunk.

Comment your code to let me know what you are trying to do, in case something doesn't work.

Turn in a knitted rmd (html or pdf) on canvas. If you can't get your document to knit when you go to turn it in, just comment out the lines of code that are causing the knit to fail, knit the document, and submit.

\hypertarget{load-the-tidyverse-lubridate-and-dataretrieval-packages.}{%
\section{1. Load the tidyverse, lubridate, and dataRetrieval packages.}\label{load-the-tidyverse-lubridate-and-dataretrieval-packages.}}

\hypertarget{read-in-the-mcdonald-hollow-dataset-in-the-project-folder.}{%
\section{2. Read in the McDonald Hollow dataset in the project folder.}\label{read-in-the-mcdonald-hollow-dataset-in-the-project-folder.}}

\hypertarget{what-are-the-data-types-of-the-first-three-columns}{%
\subsection{What are the data types of the first three columns?}\label{what-are-the-data-types-of-the-first-three-columns}}

\hypertarget{how-long-is-the-data-number-of-rows}{%
\subsection{How long is the data (number of rows)?}\label{how-long-is-the-data-number-of-rows}}

\hypertarget{what-is-the-name-of-the-last-column}{%
\subsection{What is the name of the last column?}\label{what-is-the-name-of-the-last-column}}

\hypertarget{plot-the-stage-of-the-stream-stage_m_pt-on-the-y-axis-as-a-line-and-the-date-on-the-x.-these-stage-data-are-in-meters-convert-them-to-centimeters-for-the-plot.}{%
\section{3. Plot the stage of the stream (Stage\_m\_pt) on the y axis as a line and the date on the x. These stage data are in meters, convert them to centimeters for the plot.}\label{plot-the-stage-of-the-stream-stage_m_pt-on-the-y-axis-as-a-line-and-the-date-on-the-x.-these-stage-data-are-in-meters-convert-them-to-centimeters-for-the-plot.}}

\hypertarget{for-all-plots-in-this-test-label-axes-properly-and-use-a-theme-other-than-the-default.}{%
\subsection{For all plots in this test, label axes properly and use a theme other than the default.}\label{for-all-plots-in-this-test-label-axes-properly-and-use-a-theme-other-than-the-default.}}

\hypertarget{we-want-to-look-at-the-big-event-that-happens-from-november-11-2020-to-november-27-2020.-filter-the-dataset-down-to-this-time-frame-and-save-it-separately.-make-a-plot-with-the-same-setup-as-in-3-with-these-newly-saved-data.}{%
\section{4. We want to look at the big event that happens from November 11, 2020 to November 27, 2020. Filter the dataset down to this time frame and save it separately. Make a plot with the same setup as in \#3 with these newly saved data.}\label{we-want-to-look-at-the-big-event-that-happens-from-november-11-2020-to-november-27-2020.-filter-the-dataset-down-to-this-time-frame-and-save-it-separately.-make-a-plot-with-the-same-setup-as-in-3-with-these-newly-saved-data.}}

\hypertarget{for-this-storm-we-are-curious-about-how-conductivity-changes-with-the-stream-level.-to-do-this-make-a-scatter-plot-that-shows-stage-on-the-x-axis-and-specific-conductivity-spc_mscm-on-the-y.-units-mscm-color-the-points-on-the-plot-using-the-datetime-column.-use-the-plot-to-describe-how-specific-conductivity-changes-with-stream-stage-throughout-the-storm.-not-functionally-just-how-the-values-change}{%
\section{5. For this storm, we are curious about how conductivity changes with the stream level. To do this, make a scatter plot that shows Stage on the x axis and specific conductivity (SpC\_mScm) on the y. (units: mScm) Color the points on the plot using the datetime column. Use the plot to describe how specific conductivity changes with stream stage throughout the storm. (not functionally, just how the values change)}\label{for-this-storm-we-are-curious-about-how-conductivity-changes-with-the-stream-level.-to-do-this-make-a-scatter-plot-that-shows-stage-on-the-x-axis-and-specific-conductivity-spc_mscm-on-the-y.-units-mscm-color-the-points-on-the-plot-using-the-datetime-column.-use-the-plot-to-describe-how-specific-conductivity-changes-with-stream-stage-throughout-the-storm.-not-functionally-just-how-the-values-change}}

\hypertarget{continuing-to-look-at-the-storm-as-an-exploratory-data-analysis-we-want-to-create-a-plot-that-shows-all-the-parameters-measured.-to-do-this-pivot-the-storm-event-data-so-there-is-a-column-that-has-the-values-for-all-the-parameters-measured-as-individual-rows-along-with-another-column-that-identifies-the-type-of-measurement.-then-use-facet_wrap-with-the-name-column-or-whatever-you-call-it-as-the-facet.-be-sure-to-set-the-parameters-of-facet_wrap-such-that-the-y-axes-are-all-allowed-to-be-different-ranges.}{%
\section{6. Continuing to look at the storm, as an exploratory data analysis, we want to create a plot that shows all the parameters measured. To do this, pivot the STORM EVENT data so there is a column that has the values for all the parameters measured as individual rows, along with another column that identifies the type of measurement. Then use facet\_wrap with the ``name'' column (or whatever you call it) as the facet. Be sure to set the parameters of facet\_wrap such that the y axes are all allowed to be different ranges.}\label{continuing-to-look-at-the-storm-as-an-exploratory-data-analysis-we-want-to-create-a-plot-that-shows-all-the-parameters-measured.-to-do-this-pivot-the-storm-event-data-so-there-is-a-column-that-has-the-values-for-all-the-parameters-measured-as-individual-rows-along-with-another-column-that-identifies-the-type-of-measurement.-then-use-facet_wrap-with-the-name-column-or-whatever-you-call-it-as-the-facet.-be-sure-to-set-the-parameters-of-facet_wrap-such-that-the-y-axes-are-all-allowed-to-be-different-ranges.}}

EX:\\
Date Value Name\\
10/1/20 12 Stage\\
10/1/20 6 Temp\\
\ldots.

\hypertarget{we-want-to-create-a-table-that-clearly-shows-the-differences-in-water-temperature-for-the-three-months-at-the-two-locations-flow-and-pool-in-the-full-data-set-not-the-storm-subset.-to-do-this-create-a-new-column-in-the-full-dataset-called-month-and-set-it-equal-to-the-month-of-the-datetime-column-using-the-month-function.-then-group-your-dataset-by-month-and-summarize-temperature-at-each-location-by-mean.-save-these-results-to-a-new-object-and-output-it-so-it-appears-below-your-chunk-when-you-knit.-be-sure-the-object-has-descriptive-column-names.}{%
\section{7. We want to create a table that clearly shows the differences in water temperature for the three months at the two locations (flow and pool) in the FULL data set (not the storm subset). To do this: Create a new column in the full dataset called ``month'' and set it equal to the month of the datetime column using the month() function. Then group your dataset by month and summarize temperature at each location by mean. Save these results to a new object and output it so it appears below your chunk when you knit. Be sure the object has descriptive column names.}\label{we-want-to-create-a-table-that-clearly-shows-the-differences-in-water-temperature-for-the-three-months-at-the-two-locations-flow-and-pool-in-the-full-data-set-not-the-storm-subset.-to-do-this-create-a-new-column-in-the-full-dataset-called-month-and-set-it-equal-to-the-month-of-the-datetime-column-using-the-month-function.-then-group-your-dataset-by-month-and-summarize-temperature-at-each-location-by-mean.-save-these-results-to-a-new-object-and-output-it-so-it-appears-below-your-chunk-when-you-knit.-be-sure-the-object-has-descriptive-column-names.}}

You can do this all in one statement using pipes.

\hypertarget{plot-the-distribution-of-the-flow-temperature-and-show-as-vertical-lines-on-the-plot-the-mean-median-and-iqr.-be-careful-about-how-you-show-iqr.-look-at-the-definition-and-then-think-about-how-you-would-put-it-on-the-plot.-describe-in-the-text-above-the-chunk-what-color-is-what-statistic-in-the-plot.-using-the-shape-of-the-distribution-and-the-measures-you-plotted-explain-why-you-think-the-distribution-is-normal-or-not.-what-statistical-test-could-you-perform-to-see-if-it-is-normal}{%
\section{8. Plot the distribution of the flow temperature and show as vertical lines on the plot the mean, median, and IQR. Be careful about how you show IQR. Look at the definition and then think about how you would put it on the plot. Describe in the text above the chunk what color is what statistic in the plot. Using the shape of the distribution and the measures you plotted, explain why you think the distribution is normal or not. What statistical test could you perform to see if it is normal?}\label{plot-the-distribution-of-the-flow-temperature-and-show-as-vertical-lines-on-the-plot-the-mean-median-and-iqr.-be-careful-about-how-you-show-iqr.-look-at-the-definition-and-then-think-about-how-you-would-put-it-on-the-plot.-describe-in-the-text-above-the-chunk-what-color-is-what-statistic-in-the-plot.-using-the-shape-of-the-distribution-and-the-measures-you-plotted-explain-why-you-think-the-distribution-is-normal-or-not.-what-statistical-test-could-you-perform-to-see-if-it-is-normal}}

\hypertarget{in-this-question-we-will-get-and-format-data-for-three-usgs-gages.}{%
\section{9. In this question we will get and format data for three USGS gages.}\label{in-this-question-we-will-get-and-format-data-for-three-usgs-gages.}}

Gages: 03177710, 03173000, 03177480\\
Discharge in cubic feet per second (cfs) code: 00060

\hypertarget{a.-read-and-save-the-gage-information-for-the-three-gages-using-readnwissite.}{%
\subsection{a. Read and save the gage information for the three gages using readNWISsite().}\label{a.-read-and-save-the-gage-information-for-the-three-gages-using-readnwissite.}}

\hypertarget{b.-use-the-readnwisdv-function-to-read-and-save-the-daily-discharge-values-for-the-following-three-gages-for-the-2020-water-year-10-01-2019-to-9-30-2020.-and-then-use-the-renamenwiscolumns-function-to-make-the-names-human-friendly.}{%
\subsection{b. Use the readNWISdv() function to read and save the daily discharge values for the following three gages for the 2020 water year (10-01-2019 to 9-30-2020). And then use the renameNWIScolumns() function to make the names human-friendly.}\label{b.-use-the-readnwisdv-function-to-read-and-save-the-daily-discharge-values-for-the-following-three-gages-for-the-2020-water-year-10-01-2019-to-9-30-2020.-and-then-use-the-renamenwiscolumns-function-to-make-the-names-human-friendly.}}

\hypertarget{c.-join-the-gage-site-information-from-a-to-the-data-from-b-so-you-can-reference-the-gages-by-their-names.}{%
\subsection{c.~Join the gage site information from (a) to the data from (b) so you can reference the gages by their names.}\label{c.-join-the-gage-site-information-from-a-to-the-data-from-b-so-you-can-reference-the-gages-by-their-names.}}

\hypertarget{using-the-data-from-9-plot-flow-on-the-y-axis-and-date-on-the-x-axis-showing-the-data-as-a-line-and-coloring-by-gage-name.}{%
\section{10. Using the data from \#9, Plot flow on the y axis and date on the x axis, showing the data as a line, and coloring by gage name.}\label{using-the-data-from-9-plot-flow-on-the-y-axis-and-date-on-the-x-axis-showing-the-data-as-a-line-and-coloring-by-gage-name.}}

\hypertarget{fdcs}{%
\chapter{Flow Duration Curves}\label{fdcs}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(dataRetrieval)}
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{library}\NormalTok{(patchwork)}

\FunctionTok{theme\_set}\NormalTok{(}\FunctionTok{theme\_classic}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\hypertarget{flow-duration-curves}{%
\chapter{Flow Duration Curves}\label{flow-duration-curves}}

Alright team. So far we have learned to wrangle data, make plots, and look at data distributions. Now it is time to put all that knowledge to use.

We are on our way to doing analyses of extreme discharge events: low flow statistics and flood. But in order to do that, we need to understand a common way to look at data distributions in hydrology: the flow duration curve. As you'll see below, this is basically just a different way of looking at a pdf, and it can take some getting used to. But it is also a very useful tool!

\hypertarget{get-data}{%
\section{Get data}\label{get-data}}

To start, let's grab the USGS discharge data for the gage in Linville NC from 1960 to 2020.

We will download the data using USGS dataRetrieval and look at a line plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{siteno }\OtherTok{\textless{}{-}} \StringTok{"02138500"} \CommentTok{\#Linville NC}
\NormalTok{startDate }\OtherTok{\textless{}{-}} \StringTok{"1960{-}01{-}01"}
\NormalTok{endDate }\OtherTok{\textless{}{-}} \StringTok{"2020{-}01{-}01"}
\NormalTok{parameter }\OtherTok{\textless{}{-}} \StringTok{"00060"}

\NormalTok{Qdat }\OtherTok{\textless{}{-}} \FunctionTok{readNWISdv}\NormalTok{(siteno, parameter, startDate, endDate) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{renameNWISColumns}\NormalTok{()}

\CommentTok{\#Look at the data}
\NormalTok{Qdat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Date, }\AttributeTok{y =}\NormalTok{ Flow))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-86-1.pdf}

\hypertarget{review-describe-the-distribution}{%
\section{Review: describe the distribution}\label{review-describe-the-distribution}}

Make a plot to view the distribution of the discharge data.

What is the median flow value? What does this tell us about flow at that river? How often is the river at or below that value? Could you pick that number off the plot? What about the flow the river is at or above only 5\% of the time?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Qdat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(Flow))}\SpecialCharTok{+}
  \FunctionTok{stat\_density}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \FunctionTok{median}\NormalTok{(Qdat}\SpecialCharTok{$}\NormalTok{Flow), }\AttributeTok{color =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-87-1.pdf}

\hypertarget{ecdfs}{%
\section{ECDFs}\label{ecdfs}}

Let's look at an Empirical Cumulative Density Function (ECDF) of the data.

Look at this carefully, what does it show? How is it different from the pdf of the data?

Plot the median again. Without the line on the plot, how would you tell where the median is?

Given your answer to the question above, can you determine the flow the river is at or above only 25\% of the time? Think carefully about what the y axis of the ECDF means.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Qdat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(Flow))}\SpecialCharTok{+}
  \FunctionTok{stat\_ecdf}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \FunctionTok{median}\NormalTok{(Qdat}\SpecialCharTok{$}\NormalTok{Flow), }\AttributeTok{color =} \StringTok{"red"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \FunctionTok{quantile}\NormalTok{(Qdat}\SpecialCharTok{$}\NormalTok{Flow)[}\DecValTok{4}\NormalTok{], }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-88-1.pdf}

\hypertarget{calculate-flow-exceedence-probabilities}{%
\section{Calculate flow exceedence probabilities}\label{calculate-flow-exceedence-probabilities}}

It is common to look at a similar representation of flow distributions in hydrology, but with flow on the Y axis and ``\% time flow is equaled or exceeded'' on the X axis. There are a number of ways we could make this plot: for example we could transform the axes of the plot above or we could use the function that results from the ECDF function in R to calculate exceedence probabilities at flow throughout our range of flows. But for our purposes, we are just going to calculate it manually.

We are going to calculate our own exceedence probabilities because knowing how to do this will hopefully help us understand what a flow duration curve is AND we will need to do similar things in our high and low flow analyses.

The formula for exceedence probability (P) is below. What do we need to calculate this?

Exceedence probability (P), Probability a flow is equaled or exceeded P = 100 * {[}M / (n + 1){]} M = Ranked position of the flow n = total number of observations in data record

Here's a description of what we will do: Pass our Qdat data to mutate and create a new column that is equal to the ranks of the discharge column. Then pass that result to mutate again and create another column equal to the 100 times the rank of each discharge divided by the length of the record (use length()) + 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Qdat }\OtherTok{\textless{}{-}}\NormalTok{ Qdat }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{rank =} \FunctionTok{rank}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{Flow)) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\#Flow is negative to make high flows ranked low (\#1)}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{P =} \DecValTok{100} \SpecialCharTok{*}\NormalTok{ (rank }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{length}\NormalTok{(Flow) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\hypertarget{plot-a-flow-duration-curve-using-the-probabilities}{%
\section{Plot a Flow Duration Curve using the probabilities}\label{plot-a-flow-duration-curve-using-the-probabilities}}

Now construct the following plot: A line with P on the x axis and flow on the y axis. Name the x axis ``\% Time flow equaled or exceeded'' and log the y axis.

That's a flow duration curve!

Questions about the flow duration curve: How often is a flow of 100 cfs exceeded at this gage? Is flow more variable for flows exceeded 0-25\% or of the time or 75-100\% of the time? How can you tell? These data are daily observations. Given that, what is a more accurate name for the x axis? What would the X axis be called if we were using maximum yearly data?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Qdat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ P, }\AttributeTok{y =}\NormalTok{ Flow))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{scale\_y\_log10}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"\% Time flow equalled or exceeded"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Q (cfs)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-90-1.pdf}

\hypertarget{make-an-almost-fdc-with-stat_ecdf}{%
\section{Make an almost FDC with stat\_ecdf}\label{make-an-almost-fdc-with-stat_ecdf}}

Below is an example of making a very similar plot with the stat\_ecdf() geometry in ggplot. Notice how similar the result is to the one we calculated manually.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Qdat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(Flow))}\SpecialCharTok{+}
  \FunctionTok{stat\_ecdf}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{scale\_y\_reverse}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Q (cfs)"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Probability flow is not exceeded"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-91-1.pdf}

\hypertarget{example-use-of-an-fdc}{%
\section{Example use of an FDC}\label{example-use-of-an-fdc}}

Let's explore one potential use of flow duration curves: examining the differences between two sets of flow data.

From the line plot of the discharge, it looked like the flow regime may have shifted a bit in the data between the early years and newer data. Let's use flow duration curves to examine potential differences. We can come up with groups and then use group\_by to run the analysis by groups instead of the whole dataset.

We are introducing a new function here called case\_when(). This allows you to assign values to a new column based on values in another column. In our case, we are going to name different time period in our data.

We will then group the data by these periods and calculate exceedence probabilities for each. The procedure works the same, except we add a group\_by statement before we create the rank and P columns. Then, when we plot, we can just tell ggplot to create different colored lines based on the time period names and it will plot a separate flow duration curve for each. Tidyverse FOR THE WIN!

Describe the differences in flow regime you see between the three periods.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Qdat }\OtherTok{\textless{}{-}}\NormalTok{ Qdat }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{year =} \FunctionTok{year}\NormalTok{(Date)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{period =} \FunctionTok{case\_when}\NormalTok{( year }\SpecialCharTok{\textless{}=} \DecValTok{1980} \SpecialCharTok{\textasciitilde{}} \StringTok{"1960{-}1980"}\NormalTok{,}
\NormalTok{                             year }\SpecialCharTok{\textgreater{}} \DecValTok{1980} \SpecialCharTok{\&}\NormalTok{ year }\SpecialCharTok{\textless{}=} \DecValTok{2000} \SpecialCharTok{\textasciitilde{}} \StringTok{"1980{-}2000"}\NormalTok{,}
\NormalTok{                             year }\SpecialCharTok{\textgreater{}} \DecValTok{2000} \SpecialCharTok{\textasciitilde{}} \StringTok{"2000{-}2020"}\NormalTok{))}

\NormalTok{Qdat }\OtherTok{\textless{}{-}}\NormalTok{ Qdat }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(period) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{rank =} \FunctionTok{rank}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{Flow)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{P =} \DecValTok{100} \SpecialCharTok{*}\NormalTok{ (rank }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{length}\NormalTok{(Flow) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)))}

\NormalTok{Qdat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ P, }\AttributeTok{y =}\NormalTok{ Flow, }\AttributeTok{color =}\NormalTok{ period))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{scale\_y\_log10}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"\% Time flow equalled or exceeded"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Q (cfs)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-92-1.pdf}

\hypertarget{compare-to-a-boxplot-of-the-same-data}{%
\section{Compare to a boxplot of the same data}\label{compare-to-a-boxplot-of-the-same-data}}

We are really just looking at the data distribution here. Remember another good way to compare distributions is a boxplot. Let's create a boxplot showing flows from these time periods. (we will also mess with the dimensions of the plot so the boxes aren't so wide, using fig.width and fig.height in the ``` header above the code chunk)

What are the advantages/disadvantages of the flow duration curves vs.~boxplots?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Qdat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ period, }\AttributeTok{y =}\NormalTok{ Flow)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{scale\_y\_log10}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-93-1.pdf}

\hypertarget{challenge-examining-flow-regime-change-at-the-grand-canyon}{%
\section{Challenge: Examining flow regime change at the Grand Canyon}\label{challenge-examining-flow-regime-change-at-the-grand-canyon}}

The USGS Gage ``Colorado River at Yuma, AZ'' is below the Hoover dam. The Hoover Dam closed in 1936, changing the flow of the Colorado River. Load average daily discharge data from 10-01-1905 to 10-01-1965. Use a line plot of discharge and flow duration curves to examine the differences in discharge for the periods: 1905 - 1936, 1937 - 1965.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{siteid }\OtherTok{\textless{}{-}} \StringTok{"09521000"}
\NormalTok{startDate }\OtherTok{\textless{}{-}} \StringTok{"1905{-}10{-}01"}
\NormalTok{endDate }\OtherTok{\textless{}{-}} \StringTok{"1965{-}10{-}01"}
\NormalTok{parameter }\OtherTok{\textless{}{-}} \StringTok{"00060"}

\NormalTok{WS }\OtherTok{\textless{}{-}} \FunctionTok{readNWISdv}\NormalTok{(siteid, parameter, startDate, endDate) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{renameNWISColumns}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{year =} \FunctionTok{year}\NormalTok{(Date)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{period =} \FunctionTok{case\_when}\NormalTok{( year }\SpecialCharTok{\textless{}=} \DecValTok{1936} \SpecialCharTok{\textasciitilde{}} \StringTok{"Pre Dam"}\NormalTok{,}
\NormalTok{                             year }\SpecialCharTok{\textgreater{}} \DecValTok{1936}  \SpecialCharTok{\textasciitilde{}} \StringTok{"Post Dam"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(period) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{rank =} \FunctionTok{rank}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{Flow)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{P =} \DecValTok{100} \SpecialCharTok{*}\NormalTok{ (rank }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{length}\NormalTok{(Flow) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)))}

\NormalTok{flow }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(WS, }\FunctionTok{aes}\NormalTok{(Date, Flow))}\SpecialCharTok{+}\CommentTok{\#, color = period))+}
  \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Q (cfs)"}\NormalTok{)}

\NormalTok{fdc }\OtherTok{\textless{}{-}}\NormalTok{ WS }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ P, }\AttributeTok{y =}\NormalTok{ Flow, }\AttributeTok{color =}\NormalTok{ period))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
  \CommentTok{\#scale\_y\_log10()+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"\% Time flow equalled or exceeded"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Q (cfs)"}\NormalTok{)}

\NormalTok{flow }\SpecialCharTok{/}\NormalTok{ (fdc }\SpecialCharTok{+} \FunctionTok{plot\_spacer}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-94-1.pdf}

\hypertarget{lfas}{%
\chapter{Low Flow Analysis}\label{lfas}}

Analysis based on: \url{https://github.com/DEQdsobota/Oregon7Q10/blob/master/R/Oregon7Q10.R}
And: \url{https://nepis.epa.gov/Exe/ZyPDF.cgi?Dockey=P100BK6P.txt}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(zoo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'zoo' was built under R version 3.6.2
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'zoo'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:base':
## 
##     as.Date, as.Date.numeric
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(dataRetrieval)}
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{library}\NormalTok{(moments)}
\end{Highlighting}
\end{Shaded}

\hypertarget{low-flow-analyses}{%
\chapter{Low Flow Analyses}\label{low-flow-analyses}}

\hypertarget{what-is-a-xqy-flow}{%
\section{What is a xQy flow?}\label{what-is-a-xqy-flow}}

``The 1Q10 and 7Q10 are both hydrologically based design flows. The 1Q10 is the lowest 1-day average flow that occurs (on average) once every 10 years. The 7Q10 is the lowest 7-day average flow that occurs (on average) once every 10 years.'' -EPA \url{https://www.epa.gov/ceam/definition-and-characteristics-low-flows\#1Q10}

7Q10

Once every 10 years: probability = 0.1 per year
7 day average flow based on daily flow

Download daily data for gage 02138500 Linville NC 1922-1984

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{siteno }\OtherTok{\textless{}{-}} \StringTok{"02138500"}
\NormalTok{startDate }\OtherTok{\textless{}{-}} \StringTok{"1922{-}01{-}01"}
\NormalTok{endDate }\OtherTok{\textless{}{-}} \StringTok{"1984{-}01{-}01"}
\NormalTok{parameter }\OtherTok{\textless{}{-}} \StringTok{"00060"}

\NormalTok{Qdat }\OtherTok{\textless{}{-}} \FunctionTok{readNWISdv}\NormalTok{(siteno, parameter, startDate, endDate) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{renameNWISColumns}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Create X day rolling average for 7 Q 10, 7 day rolling average

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Xday }\OtherTok{\textless{}{-}} \DecValTok{7}
\NormalTok{YrecInt }\OtherTok{\textless{}{-}} \DecValTok{10}

\NormalTok{Qdat }\OtherTok{\textless{}{-}}\NormalTok{ Qdat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{xdaymean =} \FunctionTok{rollmean}\NormalTok{(Flow, }
\NormalTok{                                            Xday, }
                                            \AttributeTok{fill =} \ConstantTok{NA}\NormalTok{, }
                                            \AttributeTok{na.rm =}\NormalTok{ F, }
                                            \AttributeTok{align =} \StringTok{"right"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Calculate lowest mean value (in the moving window) per year add ranks

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{QyearlyMins }\OtherTok{\textless{}{-}}\NormalTok{ Qdat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{year =} \FunctionTok{year}\NormalTok{(Date)) }\SpecialCharTok{\%\textgreater{}\%}
                        \FunctionTok{group\_by}\NormalTok{(year) }\SpecialCharTok{\%\textgreater{}\%}
                        \FunctionTok{summarize}\NormalTok{(}\AttributeTok{minQ =} \FunctionTok{min}\NormalTok{(xdaymean, }\AttributeTok{na.rm =}\NormalTok{ T), }
                                  \AttributeTok{lenDat =} \FunctionTok{length}\NormalTok{(Flow),}
                                  \AttributeTok{lenNAs =} \FunctionTok{sum}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(xdaymean))) }\SpecialCharTok{\%\textgreater{}\%}
                        \FunctionTok{filter}\NormalTok{(lenDat }\SpecialCharTok{\textgreater{}} \DecValTok{328} \SpecialCharTok{\&}\NormalTok{ lenNAs}\SpecialCharTok{/}\NormalTok{lenDat }\SpecialCharTok{\textless{}} \FloatTok{0.1}\NormalTok{) }\CommentTok{\#missing less than 10\% of each year and 10\% or fewer NAs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# add rank column and return interval column}
\NormalTok{QyearlyMins }\OtherTok{\textless{}{-}}\NormalTok{ QyearlyMins }\SpecialCharTok{\%\textgreater{}\%} 
                \FunctionTok{mutate}\NormalTok{(}\AttributeTok{rank =} \FunctionTok{rank}\NormalTok{(minQ, }\AttributeTok{ties.method =} \StringTok{"first"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
                \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ReturnInterval =}\NormalTok{ (}\FunctionTok{length}\NormalTok{(rank) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{rank) }\SpecialCharTok{\%\textgreater{}\%}
                \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ExceedProb =} \DecValTok{1}\SpecialCharTok{/}\NormalTok{ReturnInterval)}
      
\FunctionTok{ggplot}\NormalTok{(QyearlyMins, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ ReturnInterval, }\AttributeTok{y =}\NormalTok{ minQ))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-98-1.pdf}

\url{https://water.usgs.gov/osw/bulletin17b/dl_flow.pdf}

Pearson Type III

Flow = exp(Xbar + KS)

where:

Xbar = mean of the log discharge you are investigating

K = frequency factor

S = standard deviation of log discharges

Frequency Factor

\(K = (2 / g) * ((1 +( g * z)) / 6 - ((g ^ 2) / 36)) ^ 3 - 1)\)

Skewness

g = skewness() from moments package

Standard normal variate

z = 4.91 * ((1 / y) \^{} 0.14 - (1 - (1 / y)) \^{} 0.14)

y = recurrence interval

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Measures of the distribution}
\NormalTok{Xbar }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(}\FunctionTok{log}\NormalTok{(QyearlyMins}\SpecialCharTok{$}\NormalTok{minQ))}
\NormalTok{S    }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(}\FunctionTok{log}\NormalTok{(QyearlyMins}\SpecialCharTok{$}\NormalTok{minQ))}
\NormalTok{g    }\OtherTok{\textless{}{-}} \FunctionTok{skewness}\NormalTok{(}\FunctionTok{log}\NormalTok{(QyearlyMins}\SpecialCharTok{$}\NormalTok{minQ))}
 
  
\CommentTok{\#apply this to the data so we can see how it fits}
\NormalTok{QyearlyMins }\OtherTok{\textless{}{-}}\NormalTok{ QyearlyMins }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{z =} \FloatTok{4.91} \SpecialCharTok{*}\NormalTok{ ((}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ ReturnInterval) }\SpecialCharTok{\^{}} \FloatTok{0.14} \SpecialCharTok{{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ ReturnInterval) }\SpecialCharTok{\^{}} \FloatTok{0.14}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{K =}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ g) }\SpecialCharTok{*}\NormalTok{ (((}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ (g }\SpecialCharTok{*}\NormalTok{ z) }\SpecialCharTok{/} \DecValTok{6} \SpecialCharTok{{-}}\NormalTok{ (g }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{) }\SpecialCharTok{/} \DecValTok{36}\NormalTok{) }\SpecialCharTok{\^{}} \DecValTok{3}\NormalTok{) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Qfit =} \FunctionTok{exp}\NormalTok{(Xbar }\SpecialCharTok{+}\NormalTok{ K }\SpecialCharTok{*}\NormalTok{ S))}

\NormalTok{QyearlyMins }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ ReturnInterval, }\AttributeTok{y =}\NormalTok{ minQ, }\AttributeTok{color =} \StringTok{"Estimated"}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ ReturnInterval, }\AttributeTok{y =}\NormalTok{ Qfit, }\AttributeTok{color =} \StringTok{"Fitted"}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"X day yearly minimum"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Return Interval"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using method = 'loess' and formula 'y ~ x'
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-99-1.pdf}

Calculate 7Q10 or whatever we want following the xQy format and the values of x and y above

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#xQy ei: 7Q10}
\NormalTok{y }\OtherTok{=}\NormalTok{ YrecInt}

\CommentTok{\#Find these values based on established relationships}
\NormalTok{z    }\OtherTok{\textless{}{-}} \FloatTok{4.91} \SpecialCharTok{*}\NormalTok{ ((}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ y) }\SpecialCharTok{\^{}} \FloatTok{0.14} \SpecialCharTok{{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ y) }\SpecialCharTok{\^{}} \FloatTok{0.14}\NormalTok{)}
\NormalTok{K    }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ g) }\SpecialCharTok{*}\NormalTok{ (((}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ (g }\SpecialCharTok{*}\NormalTok{ z) }\SpecialCharTok{/} \DecValTok{6} \SpecialCharTok{{-}}\NormalTok{ (g }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{) }\SpecialCharTok{/} \DecValTok{36}\NormalTok{) }\SpecialCharTok{\^{}} \DecValTok{3}\NormalTok{) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }

\NormalTok{PearsonxQy }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(Xbar }\SpecialCharTok{+}\NormalTok{ K }\SpecialCharTok{*}\NormalTok{ S)}
\end{Highlighting}
\end{Shaded}

Distribution-free method

The expression for xQy is:

\begin{verbatim}
xQy = (1-e) X(ml) + eX(m2)

          where: [] indicates value is truncated
          X(m) = the m-th lowest annual low flow of record
          ml = [(n+1)/y]
          m2 = [(n+l)/y] + 1
          [z] = the largest integer less than or equal to z
          e = (n+l)/y - [(n+l)/y]
          This method is only appropriate when the desired return period is less than n/5 years
          
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ Xday}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ YrecInt}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(QyearlyMins}\SpecialCharTok{$}\NormalTok{minQ)}

\NormalTok{m1 }\OtherTok{\textless{}{-}} \FunctionTok{trunc}\NormalTok{((n }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{y)}
\NormalTok{m2 }\OtherTok{\textless{}{-}} \FunctionTok{trunc}\NormalTok{(((n }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{y) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}

\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ ((n }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{y) }\SpecialCharTok{{-}}\NormalTok{ m1}

\NormalTok{Xm1 }\OtherTok{\textless{}{-}}\NormalTok{ QyearlyMins}\SpecialCharTok{$}\NormalTok{minQ[QyearlyMins}\SpecialCharTok{$}\NormalTok{rank }\SpecialCharTok{==}\NormalTok{ m1]}
\NormalTok{Xm2 }\OtherTok{\textless{}{-}}\NormalTok{ QyearlyMins}\SpecialCharTok{$}\NormalTok{minQ[QyearlyMins}\SpecialCharTok{$}\NormalTok{rank }\SpecialCharTok{==}\NormalTok{ m2]}

\NormalTok{DFxQy }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{e) }\SpecialCharTok{*}\NormalTok{ Xm1 }\SpecialCharTok{+}\NormalTok{ e }\SpecialCharTok{*}\NormalTok{ Xm2}
\end{Highlighting}
\end{Shaded}

\hypertarget{floods}{%
\chapter{Flood Frequency Analysis}\label{floods}}

Load packages

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(dataRetrieval)}
\end{Highlighting}
\end{Shaded}

Get peak flow data and plot it

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{radford }\OtherTok{\textless{}{-}} \StringTok{"03171000"}

\NormalTok{peakflows }\OtherTok{\textless{}{-}} \FunctionTok{readNWISpeak}\NormalTok{(radford, }\AttributeTok{startDate =} \StringTok{"1950{-}01{-}01"}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(peakflows, }\FunctionTok{aes}\NormalTok{(peak\_dt, peak\_va))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-103-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#create rank column (minus flips the ranking)}
\CommentTok{\#then clean it up, pull out only peak value, date, rank}
\NormalTok{peakflows }\OtherTok{\textless{}{-}}\NormalTok{ peakflows }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ranks =} \FunctionTok{rank}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{peak\_va)) }\SpecialCharTok{\%\textgreater{}\%}
              \FunctionTok{select}\NormalTok{(peak\_dt, peak\_va, ranks)}

\CommentTok{\#look at it}
\FunctionTok{ggplot}\NormalTok{(peakflows, }\FunctionTok{aes}\NormalTok{(peak\_dt, peak\_va, }\AttributeTok{color =}\NormalTok{ ranks))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-104-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(peakflows)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      peak_dt peak_va ranks
## 1 1950-12-08   62200  14.0
## 2 1952-03-11   28100  53.0
## 3 1953-02-21   34900  43.5
## 4 1954-03-01   48000  28.5
## 5 1955-04-15   32100  49.0
## 6 1956-04-16   33300  47.0
\end{verbatim}

\begin{figure}
\centering
\includegraphics{images/plottingposition.png}
\caption{Plotting Position Formula}
\end{figure}

qi = Exceedance probability

N = Number of observations in your record

i = Rank of specific observation, i = 1 is the largest, i = N is the smallest.

a = constant for estimation = 0.44

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Non-exceedence probability = pi = 1 - qi

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Return period

Tp = 1/(1-p)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(peakflows}\SpecialCharTok{$}\NormalTok{peak\_dt)}
\NormalTok{a }\OtherTok{\textless{}{-}} \FloatTok{0.44}

\CommentTok{\#calculate exceedence/non{-}exceedence with gringorten and return period}
\NormalTok{peakflows }\OtherTok{\textless{}{-}}\NormalTok{ peakflows }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{qi =}\NormalTok{ (ranks }\SpecialCharTok{{-}}\NormalTok{ a) }\SpecialCharTok{/}\NormalTok{ (N }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{a))) }\SpecialCharTok{\%\textgreater{}\%}
                           \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pi =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ qi) }\SpecialCharTok{\%\textgreater{}\%}
                           \FunctionTok{mutate}\NormalTok{(}\AttributeTok{TpEst =} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{pi))}

\CommentTok{\#Plot peak flows on y and est return period on the x}
\NormalTok{peakflows }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ TpEst, }\AttributeTok{y =}\NormalTok{ peak\_va)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-105-1.pdf}

Need to fit these data to a distribution in order to make a continuous relationship we can use to predict the discharge of specific return intervals.

There are many distributions but a common one used is the Gumbel extreme value distribution.

\includegraphics{images/gumbel.png}
x is observed discharge data, u and x are parameters that shape the distribution.

We can calculate u and x in order to create a distribution that best fits our data with the following equations. Notice x bar is mean and sx2 is variance. We will need to find sx, which is the square root of the variance, also known as the standard deviation.

\begin{figure}
\centering
\includegraphics[width=2.58333in,height=\textheight]{images/gumbelparams.png}
\caption{Gumbel parameters}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xbar }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(peakflows}\SpecialCharTok{$}\NormalTok{peak\_va)}

\NormalTok{sx }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(peakflows}\SpecialCharTok{$}\NormalTok{peak\_va)}

\NormalTok{alpha }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{6}\NormalTok{)}\SpecialCharTok{*}\NormalTok{sx) }\SpecialCharTok{/}\NormalTok{ pi}

\NormalTok{u }\OtherTok{\textless{}{-}}\NormalTok{ xbar }\SpecialCharTok{{-}}\NormalTok{ (}\FloatTok{0.5772} \SpecialCharTok{*}\NormalTok{ alpha)}
\end{Highlighting}
\end{Shaded}

Now that we have the parameters that best represent our data as a Gumbel Distribution, we can use the formula to create the theoretical values for the return interval according to that distribution.

\includegraphics{images/gumbel.png} First calculate p theoretical with the equation above.

Then calculate Tp theoretical (the return period) as T was calculated above Tp = 1 / (1-p)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{peakflows }\OtherTok{\textless{}{-}}\NormalTok{ peakflows }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pTheoretical =} 
                                    \FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{((peak\_va }\SpecialCharTok{{-}}\NormalTok{ u) }\SpecialCharTok{/}\NormalTok{ alpha)))) }\SpecialCharTok{\%\textgreater{}\%}
                           \FunctionTok{mutate}\NormalTok{(}\AttributeTok{TpTheoretical =}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{pTheoretical)))}


\NormalTok{peakflows }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ TpEst, }\AttributeTok{y =}\NormalTok{ peak\_va, }\AttributeTok{color =} \StringTok{"Estimated"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ TpTheoretical, }\AttributeTok{y =}\NormalTok{ peak\_va, }\AttributeTok{color =} \StringTok{"Theoretical"}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Annual Peak Flows"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Return Period"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-107-1.pdf}

Make the same plot but show the theoretical values as a line and log the x axis with limits set to 1 - 100.

With this plot you could look up the return period for any flood or the discharge level for any return period.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{peakflows }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ TpEst, }\AttributeTok{y =}\NormalTok{ peak\_va, }\AttributeTok{color =} \StringTok{"Estimated"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ TpTheoretical, }\AttributeTok{y =}\NormalTok{ peak\_va, }\AttributeTok{color =} \StringTok{"Theoretical"}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Annual Peak Flows"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Return Period"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{(}\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{100}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using method = 'loess' and formula 'y ~ x'
\end{verbatim}

\begin{verbatim}
## Warning: Removed 1 rows containing missing values (geom_point).
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-108-1.pdf}

We can create a function that returns the return period for a flood of any magnitude for the gage we are investigating. Creating functions is a great way to streamline your workflow. You can write a function that performs an operation you need to perform a bunch of times, then just use the function rather than re-writing the code.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ReturnPeriod }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(flow, u, alpha)\{}
  
\NormalTok{  pTheoretical }\OtherTok{=} \FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{((flow }\SpecialCharTok{{-}}\NormalTok{ u) }\SpecialCharTok{/}\NormalTok{ alpha)))}
\NormalTok{  TpTheoretical }\OtherTok{=}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{pTheoretical))}
  
\NormalTok{  TpTheoretical}
\NormalTok{\}}

\FunctionTok{ReturnPeriod}\NormalTok{(}\DecValTok{120000}\NormalTok{, u, alpha)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 88.25008
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Flows }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{25000}\NormalTok{, }\DecValTok{150000}\NormalTok{, }\AttributeTok{by =} \DecValTok{1000}\NormalTok{)}

\NormalTok{RPFlows }\OtherTok{\textless{}{-}} \FunctionTok{ReturnPeriod}\NormalTok{(Flows, u, alpha)}

\NormalTok{newline }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(Flows, RPFlows)}

\FunctionTok{ggplot}\NormalTok{(newline, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ RPFlows, }\AttributeTok{y =}\NormalTok{ Flows))}\SpecialCharTok{+}
        \FunctionTok{geom\_smooth}\NormalTok{()}\SpecialCharTok{+}
        \FunctionTok{ylab}\NormalTok{(}\StringTok{"Annual Peak Flows"}\NormalTok{)}\SpecialCharTok{+}
        \FunctionTok{xlab}\NormalTok{(}\StringTok{"Return Period"}\NormalTok{)}\SpecialCharTok{+}
        \FunctionTok{scale\_x\_log10}\NormalTok{(}\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{100}\NormalTok{))}\SpecialCharTok{+}
        \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using method = 'loess' and formula 'y ~ x'
\end{verbatim}

\begin{verbatim}
## Warning: Removed 28 rows containing non-finite values (stat_smooth).
\end{verbatim}

\includegraphics{Hydroinformatics_Bookdown_files/figure-latex/unnamed-chunk-109-1.pdf}

\hypertarget{challenge-create-a-function}{%
\section{Challenge: Create a function}\label{challenge-create-a-function}}

Create a function that returns the theoretical return period for a given flood magnitude when given the the flood magnitude you want to investigate, the gage id, startdate, and enddate for the records you want.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RPusgs }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(magnitude, gageid, startDate, endDate)\{}
  
  \CommentTok{\#Read data from USGS}
\NormalTok{  peakflows }\OtherTok{\textless{}{-}} \FunctionTok{readNWISpeak}\NormalTok{(gageid, }\AttributeTok{startDate =}\NormalTok{ startDate, }\AttributeTok{endDate =}\NormalTok{ endDate)}

  \CommentTok{\#Create rank column and clean up}
\NormalTok{  peakflows }\OtherTok{\textless{}{-}}\NormalTok{ peakflows }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ranks =} \FunctionTok{rank}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{peak\_va)) }\SpecialCharTok{\%\textgreater{}\%}
              \FunctionTok{select}\NormalTok{(peak\_dt, peak\_va, ranks)}
  
  \CommentTok{\#Set N and a constants}
\NormalTok{  N }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(peakflows}\SpecialCharTok{$}\NormalTok{peak\_dt)}
\NormalTok{  a }\OtherTok{\textless{}{-}} \FloatTok{0.44}

  \CommentTok{\#calculate exceedence/non{-}exceedence with gringorten and return period estimates}
\NormalTok{  peakflows }\OtherTok{\textless{}{-}}\NormalTok{ peakflows }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{qi =}\NormalTok{ (ranks }\SpecialCharTok{{-}}\NormalTok{ a) }\SpecialCharTok{/}\NormalTok{ (N }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{a))) }\SpecialCharTok{\%\textgreater{}\%}
                           \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pi =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ qi) }\SpecialCharTok{\%\textgreater{}\%}
                           \FunctionTok{mutate}\NormalTok{(}\AttributeTok{TpEst =} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{pi))}
  
  \CommentTok{\#calculate parameters for Gumbel distribution}
\NormalTok{  xbar }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(peakflows}\SpecialCharTok{$}\NormalTok{peak\_va)}

\NormalTok{  sx }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(peakflows}\SpecialCharTok{$}\NormalTok{peak\_va)}
  
\NormalTok{  alpha }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{6}\NormalTok{)}\SpecialCharTok{*}\NormalTok{sx) }\SpecialCharTok{/}\NormalTok{ pi}
  
\NormalTok{  u }\OtherTok{\textless{}{-}}\NormalTok{ xbar }\SpecialCharTok{{-}}\NormalTok{ (}\FloatTok{0.5772} \SpecialCharTok{*}\NormalTok{ alpha)}
  
  \CommentTok{\#Calculate p and Tp (return interval) with Gumbel distribution}
\NormalTok{  pTheoretical }\OtherTok{=} \FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{((magnitude }\SpecialCharTok{{-}}\NormalTok{ u) }\SpecialCharTok{/}\NormalTok{ alpha)))}
\NormalTok{  TpTheoretical }\OtherTok{=}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{pTheoretical))}
  
\NormalTok{  TpTheoretical}
\NormalTok{\}}

\FunctionTok{RPusgs}\NormalTok{(}\DecValTok{120000}\NormalTok{, radford, }\StringTok{"1950{-}01{-}01"}\NormalTok{, }\StringTok{"2021{-}01{-}01"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 88.25008
\end{verbatim}

\hypertarget{intro}{%
\chapter{Introduction}\label{intro}}

You can label chapter and section titles using \texttt{\{\#label\}} after them, e.g., we can reference Chapter \ref{intro}. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \ref{methods}.

Figures and tables with captions will be placed in \texttt{figure} and \texttt{table} environments, respectively.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, .}\DecValTok{1}\NormalTok{, .}\DecValTok{1}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(pressure, }\AttributeTok{type =} \StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{, }\AttributeTok{pch =} \DecValTok{19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{Hydroinformatics_Bookdown_files/figure-latex/nice-fig-1} 

}

\caption{Here is a nice figure!}\label{fig:nice-fig}
\end{figure}

Reference a figure by its code chunk label with the \texttt{fig:} prefix, e.g., see Figure \ref{fig:nice-fig}. Similarly, you can reference tables generated from \texttt{knitr::kable()}, e.g., see Table \ref{tab:nice-tab}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
  \FunctionTok{head}\NormalTok{(iris, }\DecValTok{20}\NormalTok{), }\AttributeTok{caption =} \StringTok{\textquotesingle{}Here is a nice table!\textquotesingle{}}\NormalTok{,}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:nice-tab}Here is a nice table!}
\centering
\begin{tabular}[t]{rrrrl}
\toprule
Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\
\midrule
5.1 & 3.5 & 1.4 & 0.2 & setosa\\
4.9 & 3.0 & 1.4 & 0.2 & setosa\\
4.7 & 3.2 & 1.3 & 0.2 & setosa\\
4.6 & 3.1 & 1.5 & 0.2 & setosa\\
5.0 & 3.6 & 1.4 & 0.2 & setosa\\
\addlinespace
5.4 & 3.9 & 1.7 & 0.4 & setosa\\
4.6 & 3.4 & 1.4 & 0.3 & setosa\\
5.0 & 3.4 & 1.5 & 0.2 & setosa\\
4.4 & 2.9 & 1.4 & 0.2 & setosa\\
4.9 & 3.1 & 1.5 & 0.1 & setosa\\
\addlinespace
5.4 & 3.7 & 1.5 & 0.2 & setosa\\
4.8 & 3.4 & 1.6 & 0.2 & setosa\\
4.8 & 3.0 & 1.4 & 0.1 & setosa\\
4.3 & 3.0 & 1.1 & 0.1 & setosa\\
5.8 & 4.0 & 1.2 & 0.2 & setosa\\
\addlinespace
5.7 & 4.4 & 1.5 & 0.4 & setosa\\
5.4 & 3.9 & 1.3 & 0.4 & setosa\\
5.1 & 3.5 & 1.4 & 0.3 & setosa\\
5.7 & 3.8 & 1.7 & 0.3 & setosa\\
5.1 & 3.8 & 1.5 & 0.3 & setosa\\
\bottomrule
\end{tabular}
\end{table}

You can write citations, too. For example, we are using the \textbf{bookdown} package \citep{R-bookdown} in this sample book, which was built on top of R Markdown and \textbf{knitr} \citep{xie2015}.

  \bibliography{book.bib,packages.bib}

\end{document}
